[2024-07-30 14:10:15,891 INFO] Parsed 2 corpora from -data.
[2024-07-30 14:10:15,891 INFO] Loading checkpoint from /root/zindi-nmt/models/nllb-200-600M-zindi_V21_step_500.pt
[2024-07-30 14:10:19,939 INFO] Updating checkpoint vocabulary with new vocabulary
[2024-07-30 14:10:19,939 INFO] Get special vocabs from Transforms: {'src': ['</s>', 'dyu_Latn'], 'tgt': ['', 'fra_Latn']}.
[2024-07-30 14:10:20,572 INFO] The first 10 tokens of the vocabs are:['<s>', '<blank>', '</s>', '<unk>', 'an', '▁n', '▁m', '▁t', '▁k', '▁a']
[2024-07-30 14:10:20,574 INFO] The decoder start token is: </s>
[2024-07-30 14:10:20,637 INFO] Over-ride model option set to true - use with care
[2024-07-30 14:10:20,638 INFO] Option: save_model , value: /root/zindi-nmt/models/nllb-200-600M-zindi_V22 overriding model: /root/zindi-nmt/models/nllb-200-600M-zindi_V21
[2024-07-30 14:10:20,638 INFO] Option: train_from , value: /root/zindi-nmt/models/nllb-200-600M-zindi_V21_step_500.pt overriding model: /root/zindi-nmt/models/nllb-200-600M-onmt.pt
[2024-07-30 14:10:20,638 INFO] Option: dropout , value: [0.1, 0.1, 0.1] overriding model: [0.2, 0.2, 0.2]
[2024-07-30 14:10:20,638 INFO] Option: attention_dropout , value: [0.1, 0.1, 0.1] overriding model: [0.2, 0.2, 0.2]
[2024-07-30 14:10:20,638 INFO] Option: log_file , value: /root/zindi-nmt/logs/trainnllb-200-600M-zindi_V22.log overriding model: /root/zindi-nmt/logs/trainnllb-200-600M-zindi_V21.log
[2024-07-30 14:10:20,638 INFO] Building model...
[2024-07-30 14:10:28,493 INFO] Switching model to float32 for amp/apex_amp
[2024-07-30 14:10:28,493 INFO] Non quantized layer compute is fp16
[2024-07-30 14:10:28,494 INFO] Updating vocabulary embeddings with checkpoint embeddings
[2024-07-30 14:10:31,200 INFO] src: 0 new tokens
[2024-07-30 14:10:37,012 INFO] tgt: 0 new tokens
[2024-07-30 14:10:38,024 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(256206, 1024, padding_idx=1)
        )
        (pe): PositionalEncoding()
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): ModuleList(
      (0-11): 12 x TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_values): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_query): Linear(in_features=1024, out_features=1024, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=1024, bias=True)
          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(256206, 1024, padding_idx=1)
        )
        (pe): PositionalEncoding()
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (transformer_layers): ModuleList(
      (0-11): 12 x TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_values): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_query): Linear(in_features=1024, out_features=1024, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=1024, bias=True)
          (w_2): Linear(in_features=1024, out_features=1024, bias=True)
          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_values): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_query): Linear(in_features=1024, out_features=1024, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (layer_norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (generator): Linear(in_features=1024, out_features=256206, bias=True)
)
[2024-07-30 14:10:38,040 INFO] encoder: 337977344
[2024-07-30 14:10:38,040 INFO] decoder: 126283982
[2024-07-30 14:10:38,040 INFO] * number of parameters: 464261326
[2024-07-30 14:10:38,045 INFO] Trainable parameters = {'torch.float32': 464261326, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}
[2024-07-30 14:10:38,045 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}
[2024-07-30 14:10:38,045 INFO]  * src vocab size = 256206
[2024-07-30 14:10:38,045 INFO]  * tgt vocab size = 256206
[2024-07-30 14:10:38,929 INFO] Starting training on GPU: [0]
[2024-07-30 14:10:38,929 INFO] Start training loop and validate every 100 steps...
[2024-07-30 14:10:38,930 INFO] Scoring with: ['sentencepiece', 'prefix', 'suffix', 'filtertoolong']
[2024-07-30 14:11:42,338 INFO] Step 10/10000; acc: 63.7; ppl:  23.3; xent: 3.1; lr: 0.00069; sents:   12536; bsz: 2240/2391/157; 2827/3016 tok/s;     63 sec;
[2024-07-30 14:12:16,490 INFO] Step 20/10000; acc: 64.9; ppl:  22.0; xent: 3.1; lr: 0.00131; sents:   12355; bsz: 2324/2439/154; 5445/5714 tok/s;     98 sec;
[2024-07-30 14:12:49,985 INFO] Step 30/10000; acc: 64.3; ppl:  22.5; xent: 3.1; lr: 0.00194; sents:   12581; bsz: 2154/2363/157; 5146/5644 tok/s;    131 sec;
[2024-07-30 14:13:21,441 INFO] Step 40/10000; acc: 64.7; ppl:  21.7; xent: 3.1; lr: 0.00256; sents:   12325; bsz: 2389/2492/154; 6076/6337 tok/s;    163 sec;
[2024-07-30 14:13:54,887 INFO] Step 50/10000; acc: 61.0; ppl:  26.4; xent: 3.3; lr: 0.00319; sents:    9757; bsz: 2197/2305/122; 5255/5513 tok/s;    196 sec;
[2024-07-30 14:14:28,036 INFO] Step 60/10000; acc: 63.2; ppl:  23.8; xent: 3.2; lr: 0.00381; sents:   13403; bsz: 2357/2466/168; 5689/5951 tok/s;    229 sec;
[2024-07-30 14:15:01,042 INFO] Step 70/10000; acc: 62.1; ppl:  25.2; xent: 3.2; lr: 0.00444; sents:   12543; bsz: 2351/2508/157; 5698/6078 tok/s;    262 sec;
[2024-07-30 14:15:32,291 INFO] Step 80/10000; acc: 61.9; ppl:  25.1; xent: 3.2; lr: 0.00506; sents:   12509; bsz: 2202/2501/156; 5637/6404 tok/s;    293 sec;
[2024-07-30 14:16:06,204 INFO] Step 90/10000; acc: 60.5; ppl:  26.5; xent: 3.3; lr: 0.00569; sents:   10706; bsz: 2349/2517/134; 5542/5937 tok/s;    327 sec;
[2024-07-30 14:16:39,762 INFO] Step 100/10000; acc: 59.0; ppl:  28.6; xent: 3.4; lr: 0.00622; sents:   10493; bsz: 2307/2406/131; 5501/5735 tok/s;    361 sec;
[2024-07-30 14:17:11,674 INFO] valid stats calculation
                           took: 31.894508123397827 s.
[2024-07-30 14:17:11,685 INFO] Train perplexity: 24.4066
[2024-07-30 14:17:11,685 INFO] Train accuracy: 62.5454
[2024-07-30 14:17:11,685 INFO] Sentences processed: 119208
[2024-07-30 14:17:11,685 INFO] Average bsz: 2287/2439/149
[2024-07-30 14:17:11,685 INFO] Validation perplexity: 48.5019
[2024-07-30 14:17:11,685 INFO] Validation accuracy: 53.9828
[2024-07-30 14:17:11,685 INFO] Model is improving ppl: inf --> 48.5019.
[2024-07-30 14:17:11,685 INFO] Model is improving acc: -inf --> 53.9828.
[2024-07-30 14:17:44,129 INFO] Step 110/10000; acc: 60.1; ppl:  27.5; xent: 3.3; lr: 0.00593; sents:   12097; bsz: 2475/2487/151; 3076/3091 tok/s;    425 sec;
[2024-07-30 14:18:16,323 INFO] Step 120/10000; acc: 57.9; ppl:  30.7; xent: 3.4; lr: 0.00568; sents:    9742; bsz: 2112/2296/122; 5248/5705 tok/s;    457 sec;
[2024-07-30 14:18:46,843 INFO] Step 130/10000; acc: 57.5; ppl:  31.2; xent: 3.4; lr: 0.00546; sents:    8757; bsz: 2290/2401/109; 6002/6293 tok/s;    488 sec;
[2024-07-30 14:19:20,726 INFO] Step 140/10000; acc: 58.5; ppl:  29.7; xent: 3.4; lr: 0.00526; sents:    9649; bsz: 2294/2412/121; 5416/5694 tok/s;    522 sec;
[2024-07-30 14:19:55,227 INFO] Step 150/10000; acc: 60.1; ppl:  27.5; xent: 3.3; lr: 0.00509; sents:   10497; bsz: 2238/2393/131; 5189/5548 tok/s;    556 sec;
[2024-07-30 14:20:29,542 INFO] Step 160/10000; acc: 60.5; ppl:  27.1; xent: 3.3; lr: 0.00493; sents:   11067; bsz: 2259/2370/138; 5266/5525 tok/s;    591 sec;
[2024-07-30 14:21:03,540 INFO] Step 170/10000; acc: 61.4; ppl:  25.9; xent: 3.3; lr: 0.00478; sents:   11684; bsz: 2281/2447/146; 5367/5758 tok/s;    625 sec;
[2024-07-30 14:21:37,769 INFO] Step 180/10000; acc: 62.6; ppl:  24.0; xent: 3.2; lr: 0.00465; sents:   11435; bsz: 2274/2450/143; 5314/5726 tok/s;    659 sec;
[2024-07-30 14:22:12,254 INFO] Step 190/10000; acc: 62.8; ppl:  23.7; xent: 3.2; lr: 0.00452; sents:   11200; bsz: 2261/2461/140; 5246/5709 tok/s;    693 sec;
[2024-07-30 14:22:46,992 INFO] Step 200/10000; acc: 63.5; ppl:  22.9; xent: 3.1; lr: 0.00441; sents:   12565; bsz: 2308/2570/157; 5316/5918 tok/s;    728 sec;
[2024-07-30 14:23:19,780 INFO] valid stats calculation
                           took: 32.77118444442749 s.
[2024-07-30 14:23:19,793 INFO] Train perplexity: 25.5876
[2024-07-30 14:23:19,793 INFO] Train accuracy: 61.5346
[2024-07-30 14:23:19,793 INFO] Sentences processed: 227901
[2024-07-30 14:23:19,793 INFO] Average bsz: 2283/2434/142
[2024-07-30 14:23:19,793 INFO] Validation perplexity: 47.2017
[2024-07-30 14:23:19,793 INFO] Validation accuracy: 54.4235
[2024-07-30 14:23:19,793 INFO] Model is improving ppl: 48.5019 --> 47.2017.
[2024-07-30 14:23:19,794 INFO] Model is improving acc: 53.9828 --> 54.4235.
[2024-07-30 14:23:53,462 INFO] Step 210/10000; acc: 63.6; ppl:  22.7; xent: 3.1; lr: 0.00430; sents:   11127; bsz: 2197/2271/139; 2644/2733 tok/s;    795 sec;
[2024-07-30 14:24:27,847 INFO] Step 220/10000; acc: 61.5; ppl:  25.1; xent: 3.2; lr: 0.00420; sents:    9265; bsz: 2248/2401/116; 5230/5586 tok/s;    829 sec;
[2024-07-30 14:25:01,805 INFO] Step 230/10000; acc: 62.2; ppl:  24.3; xent: 3.2; lr: 0.00411; sents:   10299; bsz: 2256/2333/129; 5316/5497 tok/s;    863 sec;
[2024-07-30 14:25:35,542 INFO] Step 240/10000; acc: 64.1; ppl:  22.2; xent: 3.1; lr: 0.00403; sents:   12048; bsz: 2307/2407/151; 5470/5708 tok/s;    897 sec;
[2024-07-30 14:26:07,249 INFO] Step 250/10000; acc: 64.4; ppl:  22.0; xent: 3.1; lr: 0.00394; sents:   12953; bsz: 2208/2462/162; 5571/6213 tok/s;    928 sec;
[2024-07-30 14:26:42,343 INFO] Step 260/10000; acc: 64.2; ppl:  22.0; xent: 3.1; lr: 0.00387; sents:   11631; bsz: 2197/2372/145; 5008/5408 tok/s;    963 sec;
[2024-07-30 14:27:16,980 INFO] Step 270/10000; acc: 64.1; ppl:  22.2; xent: 3.1; lr: 0.00380; sents:   11722; bsz: 2413/2443/147; 5572/5642 tok/s;    998 sec;
[2024-07-30 14:27:49,384 INFO] Step 280/10000; acc: 65.1; ppl:  21.3; xent: 3.1; lr: 0.00373; sents:   12741; bsz: 2263/2390/159; 5588/5900 tok/s;   1030 sec;
[2024-07-30 14:28:23,177 INFO] Step 290/10000; acc: 63.6; ppl:  22.8; xent: 3.1; lr: 0.00366; sents:   11308; bsz: 2321/2428/141; 5494/5748 tok/s;   1064 sec;
[2024-07-30 14:28:57,108 INFO] Step 300/10000; acc: 64.4; ppl:  21.9; xent: 3.1; lr: 0.00360; sents:   12481; bsz: 2297/2528/156; 5415/5961 tok/s;   1098 sec;
[2024-07-30 14:29:30,627 INFO] valid stats calculation
                           took: 33.50302481651306 s.
[2024-07-30 14:29:30,634 INFO] Train perplexity: 24.5645
[2024-07-30 14:29:30,635 INFO] Train accuracy: 62.2677
[2024-07-30 14:29:30,635 INFO] Sentences processed: 343476
[2024-07-30 14:29:30,635 INFO] Average bsz: 2279/2424/143
[2024-07-30 14:29:30,635 INFO] Validation perplexity: 45.051
[2024-07-30 14:29:30,635 INFO] Validation accuracy: 55.261
[2024-07-30 14:29:30,635 INFO] Model is improving ppl: 47.2017 --> 45.051.
[2024-07-30 14:29:30,635 INFO] Model is improving acc: 54.4235 --> 55.261.
[2024-07-30 14:30:03,809 INFO] Step 310/10000; acc: 65.2; ppl:  21.1; xent: 3.1; lr: 0.00354; sents:   11416; bsz: 2270/2409/143; 2722/2889 tok/s;   1165 sec;
[2024-07-30 14:30:34,553 INFO] Step 320/10000; acc: 64.7; ppl:  21.5; xent: 3.1; lr: 0.00349; sents:   10986; bsz: 2331/2486/137; 6067/6470 tok/s;   1196 sec;
[2024-07-30 14:31:05,788 INFO] Step 330/10000; acc: 63.2; ppl:  23.4; xent: 3.2; lr: 0.00344; sents:    9918; bsz: 2250/2353/124; 5763/6026 tok/s;   1227 sec;
[2024-07-30 14:31:41,920 INFO] Step 340/10000; acc: 64.1; ppl:  22.1; xent: 3.1; lr: 0.00338; sents:   10853; bsz: 2269/2393/136; 5025/5298 tok/s;   1263 sec;
[2024-07-30 14:32:14,792 INFO] Step 350/10000; acc: 66.8; ppl:  19.2; xent: 3.0; lr: 0.00334; sents:   11970; bsz: 2197/2311/150; 5347/5624 tok/s;   1296 sec;
[2024-07-30 14:32:47,435 INFO] Step 360/10000; acc: 66.9; ppl:  18.8; xent: 2.9; lr: 0.00329; sents:   11802; bsz: 2286/2453/148; 5602/6012 tok/s;   1329 sec;
[2024-07-30 14:33:19,229 INFO] Step 370/10000; acc: 65.9; ppl:  19.7; xent: 3.0; lr: 0.00324; sents:   10544; bsz: 2307/2387/132; 5806/6006 tok/s;   1360 sec;
[2024-07-30 14:33:50,648 INFO] Step 380/10000; acc: 66.8; ppl:  19.0; xent: 2.9; lr: 0.00320; sents:   11983; bsz: 2280/2475/150; 5805/6301 tok/s;   1392 sec;
[2024-07-30 14:34:24,944 INFO] Step 390/10000; acc: 67.0; ppl:  18.8; xent: 2.9; lr: 0.00316; sents:   12468; bsz: 2382/2513/156; 5557/5862 tok/s;   1426 sec;
[2024-07-30 14:34:57,114 INFO] Step 400/10000; acc: 66.4; ppl:  19.4; xent: 3.0; lr: 0.00312; sents:   11439; bsz: 2283/2348/143; 5677/5839 tok/s;   1458 sec;
[2024-07-30 14:35:30,226 INFO] valid stats calculation
                           took: 33.096346616744995 s.
[2024-07-30 14:35:30,240 INFO] Train perplexity: 23.4055
[2024-07-30 14:35:30,240 INFO] Train accuracy: 63.1232
[2024-07-30 14:35:30,240 INFO] Sentences processed: 456855
[2024-07-30 14:35:30,240 INFO] Average bsz: 2281/2421/143
[2024-07-30 14:35:30,240 INFO] Validation perplexity: 45.312
[2024-07-30 14:35:30,240 INFO] Validation accuracy: 56.0332
[2024-07-30 14:35:30,241 INFO] Stalled patience: 14/15
[2024-07-30 14:36:02,529 INFO] Step 410/10000; acc: 66.1; ppl:  19.9; xent: 3.0; lr: 0.00308; sents:   12063; bsz: 2239/2514/151; 2739/3074 tok/s;   1524 sec;
[2024-07-30 14:36:35,268 INFO] Step 420/10000; acc: 66.0; ppl:  20.0; xent: 3.0; lr: 0.00305; sents:   11346; bsz: 2279/2357/142; 5570/5760 tok/s;   1556 sec;
[2024-07-30 14:37:06,563 INFO] Step 430/10000; acc: 66.3; ppl:  19.6; xent: 3.0; lr: 0.00301; sents:   11611; bsz: 2383/2448/145; 6093/6257 tok/s;   1588 sec;
[2024-07-30 14:37:41,325 INFO] Step 440/10000; acc: 66.3; ppl:  19.6; xent: 3.0; lr: 0.00298; sents:   11863; bsz: 2256/2429/148; 5192/5590 tok/s;   1622 sec;
[2024-07-30 14:38:16,527 INFO] Step 450/10000; acc: 65.1; ppl:  20.9; xent: 3.0; lr: 0.00294; sents:   10335; bsz: 2115/2316/129; 4807/5262 tok/s;   1658 sec;
[2024-07-30 14:38:49,810 INFO] Step 460/10000; acc: 64.6; ppl:  21.2; xent: 3.1; lr: 0.00291; sents:    9520; bsz: 2195/2271/119; 5276/5459 tok/s;   1691 sec;
[2024-07-30 14:39:24,203 INFO] Step 470/10000; acc: 65.3; ppl:  20.6; xent: 3.0; lr: 0.00288; sents:   10895; bsz: 2244/2482/136; 5219/5774 tok/s;   1725 sec;
[2024-07-30 14:39:59,146 INFO] Step 480/10000; acc: 64.3; ppl:  22.0; xent: 3.1; lr: 0.00285; sents:   10495; bsz: 2144/2356/131; 4908/5395 tok/s;   1760 sec;
[2024-07-30 14:40:33,406 INFO] Step 490/10000; acc: 65.4; ppl:  20.7; xent: 3.0; lr: 0.00282; sents:   12092; bsz: 2370/2458/151; 5534/5740 tok/s;   1794 sec;
[2024-07-30 14:41:07,073 INFO] Step 500/10000; acc: 64.4; ppl:  22.0; xent: 3.1; lr: 0.00279; sents:   10354; bsz: 2204/2400/129; 5238/5703 tok/s;   1828 sec;
[2024-07-30 14:41:41,597 INFO] valid stats calculation
                           took: 34.51432657241821 s.
[2024-07-30 14:41:41,610 INFO] Train perplexity: 22.8206
[2024-07-30 14:41:41,610 INFO] Train accuracy: 63.5735
[2024-07-30 14:41:41,610 INFO] Sentences processed: 567429
[2024-07-30 14:41:41,610 INFO] Average bsz: 2273/2417/142
[2024-07-30 14:41:41,610 INFO] Validation perplexity: 43.7605
[2024-07-30 14:41:41,610 INFO] Validation accuracy: 56.5459
[2024-07-30 14:41:41,611 INFO] Model is improving ppl: 45.051 --> 43.7605.
[2024-07-30 14:41:41,611 INFO] Model is improving acc: 55.261 --> 56.5459.
[2024-07-30 14:41:41,700 INFO] Saving checkpoint /root/zindi-nmt/models/nllb-200-600M-zindi_V22_step_500.pt
[2024-07-30 14:42:23,446 INFO] Step 510/10000; acc: 67.2; ppl:  18.9; xent: 2.9; lr: 0.00276; sents:   13072; bsz: 2227/2385/163; 2333/2498 tok/s;   1905 sec;
[2024-07-30 14:42:57,708 INFO] Step 520/10000; acc: 68.1; ppl:  17.7; xent: 2.9; lr: 0.00274; sents:   11136; bsz: 2202/2401/139; 5141/5606 tok/s;   1939 sec;
[2024-07-30 14:43:32,518 INFO] Step 530/10000; acc: 67.6; ppl:  17.9; xent: 2.9; lr: 0.00271; sents:   10164; bsz: 2228/2426/127; 5120/5575 tok/s;   1974 sec;
[2024-07-30 14:44:07,234 INFO] Step 540/10000; acc: 68.4; ppl:  17.3; xent: 2.9; lr: 0.00269; sents:   10861; bsz: 2175/2347/136; 5012/5408 tok/s;   2008 sec;
[2024-07-30 14:44:40,861 INFO] Step 550/10000; acc: 68.3; ppl:  17.5; xent: 2.9; lr: 0.00266; sents:   11116; bsz: 2264/2484/139; 5387/5909 tok/s;   2042 sec;
[2024-07-30 14:45:14,622 INFO] Step 560/10000; acc: 68.9; ppl:  16.9; xent: 2.8; lr: 0.00264; sents:   12306; bsz: 2309/2438/154; 5471/5777 tok/s;   2076 sec;
[2024-07-30 14:45:48,225 INFO] Step 570/10000; acc: 69.1; ppl:  16.7; xent: 2.8; lr: 0.00262; sents:   12160; bsz: 2371/2473/152; 5646/5889 tok/s;   2109 sec;
[2024-07-30 14:46:19,753 INFO] Step 580/10000; acc: 69.3; ppl:  16.5; xent: 2.8; lr: 0.00259; sents:   12214; bsz: 2326/2404/153; 5903/6101 tok/s;   2141 sec;
[2024-07-30 14:46:55,697 INFO] Step 590/10000; acc: 69.0; ppl:  16.9; xent: 2.8; lr: 0.00257; sents:   12056; bsz: 2225/2459/151; 4951/5473 tok/s;   2177 sec;
[2024-07-30 14:47:32,041 INFO] Step 600/10000; acc: 68.2; ppl:  17.6; xent: 2.9; lr: 0.00255; sents:   11600; bsz: 2302/2499/145; 5068/5501 tok/s;   2213 sec;
[2024-07-30 14:48:04,428 INFO] valid stats calculation
                           took: 32.36990261077881 s.
[2024-07-30 14:48:04,446 INFO] Train perplexity: 21.7991
[2024-07-30 14:48:04,446 INFO] Train accuracy: 64.3836
[2024-07-30 14:48:04,446 INFO] Sentences processed: 684114
[2024-07-30 14:48:04,446 INFO] Average bsz: 2271/2420/143
[2024-07-30 14:48:04,446 INFO] Validation perplexity: 47.9805
[2024-07-30 14:48:04,446 INFO] Validation accuracy: 55.5544
[2024-07-30 14:48:04,446 INFO] Decreasing patience: 14/15
[2024-07-30 14:48:38,058 INFO] Step 610/10000; acc: 68.4; ppl:  17.4; xent: 2.9; lr: 0.00253; sents:   11718; bsz: 2299/2476/146; 2786/3001 tok/s;   2279 sec;
[2024-07-30 14:49:10,550 INFO] Step 620/10000; acc: 68.2; ppl:  17.5; xent: 2.9; lr: 0.00251; sents:   11008; bsz: 2132/2389/138; 5249/5881 tok/s;   2312 sec;
[2024-07-30 14:49:43,336 INFO] Step 630/10000; acc: 69.0; ppl:  17.0; xent: 2.8; lr: 0.00249; sents:   12748; bsz: 2402/2558/159; 5861/6243 tok/s;   2344 sec;
[2024-07-30 14:50:17,088 INFO] Step 640/10000; acc: 67.4; ppl:  18.2; xent: 2.9; lr: 0.00247; sents:   10585; bsz: 2318/2368/132; 5495/5613 tok/s;   2378 sec;
[2024-07-30 14:50:50,798 INFO] Step 650/10000; acc: 67.7; ppl:  17.9; xent: 2.9; lr: 0.00245; sents:   10335; bsz: 2259/2369/129; 5361/5623 tok/s;   2412 sec;
[2024-07-30 14:51:24,061 INFO] Step 660/10000; acc: 67.6; ppl:  18.1; xent: 2.9; lr: 0.00243; sents:   10903; bsz: 2373/2518/136; 5707/6056 tok/s;   2445 sec;
[2024-07-30 14:51:57,091 INFO] Step 670/10000; acc: 68.2; ppl:  17.7; xent: 2.9; lr: 0.00241; sents:   11356; bsz: 2322/2384/142; 5624/5775 tok/s;   2478 sec;
[2024-07-30 14:52:30,812 INFO] Step 680/10000; acc: 70.8; ppl:  15.3; xent: 2.7; lr: 0.00240; sents:   11916; bsz: 2460/2508/149; 5836/5949 tok/s;   2512 sec;
[2024-07-30 14:53:03,431 INFO] Step 690/10000; acc: 71.1; ppl:  14.9; xent: 2.7; lr: 0.00238; sents:   12215; bsz: 2390/2491/153; 5862/6109 tok/s;   2545 sec;
[2024-07-30 14:53:37,235 INFO] Step 700/10000; acc: 71.2; ppl:  14.9; xent: 2.7; lr: 0.00236; sents:   12384; bsz: 2281/2493/155; 5398/5899 tok/s;   2578 sec;
[2024-07-30 14:54:09,341 INFO] valid stats calculation
                           took: 32.089160442352295 s.
[2024-07-30 14:54:09,348 INFO] Train perplexity: 20.9955
[2024-07-30 14:54:09,349 INFO] Train accuracy: 65.0493
[2024-07-30 14:54:09,349 INFO] Sentences processed: 799282
[2024-07-30 14:54:09,349 INFO] Average bsz: 2279/2425/143
[2024-07-30 14:54:09,349 INFO] Validation perplexity: 49.8613
[2024-07-30 14:54:09,349 INFO] Validation accuracy: 55.5338
[2024-07-30 14:54:09,349 INFO] Decreasing patience: 13/15
[2024-07-30 14:54:41,378 INFO] Step 710/10000; acc: 70.9; ppl:  15.1; xent: 2.7; lr: 0.00234; sents:   11950; bsz: 2158/2410/149; 2692/3006 tok/s;   2642 sec;
[2024-07-30 14:55:15,290 INFO] Step 720/10000; acc: 70.7; ppl:  15.2; xent: 2.7; lr: 0.00233; sents:   11618; bsz: 2306/2410/145; 5440/5685 tok/s;   2676 sec;
[2024-07-30 14:55:49,512 INFO] Step 730/10000; acc: 71.0; ppl:  15.1; xent: 2.7; lr: 0.00231; sents:   12440; bsz: 2340/2465/156; 5470/5762 tok/s;   2711 sec;
[2024-07-30 14:56:21,654 INFO] Step 740/10000; acc: 70.3; ppl:  15.6; xent: 2.7; lr: 0.00230; sents:   11818; bsz: 2217/2487/148; 5518/6189 tok/s;   2743 sec;
[2024-07-30 14:56:52,715 INFO] Step 750/10000; acc: 70.6; ppl:  15.4; xent: 2.7; lr: 0.00228; sents:   11576; bsz: 2148/2395/145; 5532/6169 tok/s;   2774 sec;
[2024-07-30 14:57:26,556 INFO] Step 760/10000; acc: 69.0; ppl:  16.5; xent: 2.8; lr: 0.00227; sents:    9638; bsz: 2120/2352/120; 5012/5561 tok/s;   2808 sec;
[2024-07-30 14:57:59,938 INFO] Step 770/10000; acc: 70.3; ppl:  15.6; xent: 2.7; lr: 0.00225; sents:   10894; bsz: 2279/2416/136; 5461/5791 tok/s;   2841 sec;
[2024-07-30 14:58:33,298 INFO] Step 780/10000; acc: 70.2; ppl:  15.7; xent: 2.8; lr: 0.00224; sents:   11794; bsz: 2285/2465/147; 5479/5910 tok/s;   2874 sec;
[2024-07-30 14:59:07,075 INFO] Step 790/10000; acc: 70.3; ppl:  15.6; xent: 2.7; lr: 0.00222; sents:   10657; bsz: 2282/2355/133; 5404/5578 tok/s;   2908 sec;
[2024-07-30 14:59:41,168 INFO] Step 800/10000; acc: 70.3; ppl:  15.6; xent: 2.7; lr: 0.00221; sents:   10740; bsz: 2332/2383/134; 5471/5592 tok/s;   2942 sec;
[2024-07-30 15:00:14,355 INFO] valid stats calculation
                           took: 33.1766676902771 s.
[2024-07-30 15:00:14,369 INFO] Train perplexity: 20.2229
[2024-07-30 15:00:14,369 INFO] Train accuracy: 65.7128
[2024-07-30 15:00:14,369 INFO] Sentences processed: 912407
[2024-07-30 15:00:14,369 INFO] Average bsz: 2275/2423/143
[2024-07-30 15:00:14,370 INFO] Validation perplexity: 49.3107
[2024-07-30 15:00:14,370 INFO] Validation accuracy: 56.1515
[2024-07-30 15:00:14,370 INFO] Decreasing patience: 12/15
[2024-07-30 15:00:48,205 INFO] Step 810/10000; acc: 70.1; ppl:  15.8; xent: 2.8; lr: 0.00219; sents:   11642; bsz: 2299/2368/146; 2744/2826 tok/s;   3009 sec;
[2024-07-30 15:01:22,952 INFO] Step 820/10000; acc: 70.0; ppl:  15.8; xent: 2.8; lr: 0.00218; sents:   11418; bsz: 2301/2411/143; 5298/5551 tok/s;   3044 sec;
[2024-07-30 15:01:57,749 INFO] Step 830/10000; acc: 69.4; ppl:  16.3; xent: 2.8; lr: 0.00217; sents:   10175; bsz: 2282/2446/127; 5247/5624 tok/s;   3079 sec;
[2024-07-30 15:02:31,668 INFO] Step 840/10000; acc: 70.3; ppl:  15.6; xent: 2.7; lr: 0.00216; sents:   10742; bsz: 2353/2397/134; 5549/5654 tok/s;   3113 sec;
[2024-07-30 15:03:04,710 INFO] Step 850/10000; acc: 71.8; ppl:  14.5; xent: 2.7; lr: 0.00214; sents:   10096; bsz: 2180/2276/126; 5279/5510 tok/s;   3146 sec;
[2024-07-30 15:03:38,304 INFO] Step 860/10000; acc: 73.0; ppl:  13.7; xent: 2.6; lr: 0.00213; sents:   12275; bsz: 2272/2453/153; 5410/5841 tok/s;   3179 sec;
[2024-07-30 15:04:09,042 INFO] Step 870/10000; acc: 72.9; ppl:  13.8; xent: 2.6; lr: 0.00212; sents:   11756; bsz: 2276/2385/147; 5924/6208 tok/s;   3210 sec;
[2024-07-30 15:04:42,952 INFO] Step 880/10000; acc: 72.0; ppl:  14.4; xent: 2.7; lr: 0.00211; sents:   10722; bsz: 2204/2405/134; 5200/5675 tok/s;   3244 sec;
[2024-07-30 15:05:16,736 INFO] Step 890/10000; acc: 72.3; ppl:  14.2; xent: 2.7; lr: 0.00209; sents:   10398; bsz: 2351/2428/130; 5568/5749 tok/s;   3278 sec;
[2024-07-30 15:05:51,046 INFO] Step 900/10000; acc: 72.7; ppl:  13.9; xent: 2.6; lr: 0.00208; sents:   12578; bsz: 2273/2484/157; 5300/5791 tok/s;   3312 sec;
[2024-07-30 15:06:23,381 INFO] valid stats calculation
                           took: 32.32566857337952 s.
[2024-07-30 15:06:23,395 INFO] Train perplexity: 19.5337
[2024-07-30 15:06:23,395 INFO] Train accuracy: 66.3457
[2024-07-30 15:06:23,395 INFO] Sentences processed: 1.02421e+06
[2024-07-30 15:06:23,395 INFO] Average bsz: 2275/2421/142
[2024-07-30 15:06:23,395 INFO] Validation perplexity: 50.2743
[2024-07-30 15:06:23,395 INFO] Validation accuracy: 56.343
[2024-07-30 15:06:23,395 INFO] Decreasing patience: 11/15
[2024-07-30 15:06:54,507 INFO] Step 910/10000; acc: 72.5; ppl:  14.1; xent: 2.6; lr: 0.00207; sents:   11994; bsz: 2407/2484/150; 3034/3132 tok/s;   3376 sec;
[2024-07-30 15:07:23,891 INFO] Step 920/10000; acc: 72.1; ppl:  14.3; xent: 2.7; lr: 0.00206; sents:   11859; bsz: 2264/2485/148; 6163/6765 tok/s;   3405 sec;
[2024-07-30 15:07:57,764 INFO] Step 930/10000; acc: 71.5; ppl:  14.6; xent: 2.7; lr: 0.00205; sents:   11115; bsz: 2261/2386/139; 5340/5635 tok/s;   3439 sec;
[2024-07-30 15:08:33,372 INFO] Step 940/10000; acc: 71.9; ppl:  14.4; xent: 2.7; lr: 0.00204; sents:    9802; bsz: 2323/2332/123; 5219/5238 tok/s;   3474 sec;
[2024-07-30 15:09:07,931 INFO] Step 950/10000; acc: 72.2; ppl:  14.3; xent: 2.7; lr: 0.00203; sents:   11146; bsz: 2337/2458/139; 5409/5691 tok/s;   3509 sec;
