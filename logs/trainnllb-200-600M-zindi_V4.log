[2024-07-27 13:06:24,187 INFO] Parsed 1 corpora from -data.
[2024-07-27 13:06:24,187 INFO] Loading checkpoint from /root/projects/zindi/nmt_train/models/nllb-200-600M-zindi_V3_step_1000.pt
[2024-07-27 13:06:27,058 INFO] Updating checkpoint vocabulary with new vocabulary
[2024-07-27 13:06:27,059 INFO] Get special vocabs from Transforms: {'src': ['', '', 'dyu_Latn', '</s>'], 'tgt': ['', '', 'fra_Latn']}.
[2024-07-27 13:06:27,646 INFO] The first 10 tokens of the vocabs are:['', '<s>', '<blank>', '</s>', '<unk>', 'an', '▁n', '▁m', '▁t', '▁k']
[2024-07-27 13:06:27,648 INFO] The decoder start token is: </s>
[2024-07-27 13:06:27,713 INFO] Over-ride model option set to true - use with care
[2024-07-27 13:06:27,713 INFO] Option: save_model , value: /root/projects/zindi/nmt_train/models/nllb-200-600M-zindi_V4 overriding model: /root/projects/zindi/nmt_train/models/nllb-200-600M-zindi_V3
[2024-07-27 13:06:27,714 INFO] Option: train_from , value: /root/projects/zindi/nmt_train/models/nllb-200-600M-zindi_V3_step_1000.pt overriding model: /root/projects/zindi/nmt_train/models/nllb-200-600M-zindi_V2_step_500.pt
[2024-07-27 13:06:27,714 INFO] Option: log_file , value: /root/projects/zindi/nmt_train/trainnllb-200-600M-zindi_V4.log overriding model: /root/projects/zindi/nmt_train/trainnllb-200-600M-zindi_V3.log
[2024-07-27 13:06:27,714 INFO] Building model...
[2024-07-27 13:06:36,774 INFO] Switching model to float32 for amp/apex_amp
[2024-07-27 13:06:36,775 INFO] Non quantized layer compute is fp16
[2024-07-27 13:06:36,775 INFO] Updating vocabulary embeddings with checkpoint embeddings
[2024-07-27 13:06:38,922 INFO] src: 0 new tokens
[2024-07-27 13:06:43,482 INFO] tgt: 0 new tokens
[2024-07-27 13:06:45,054 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(270987, 1024, padding_idx=2)
        )
        (pe): PositionalEncoding()
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): ModuleList(
      (0-23): 24 x TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_values): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_query): Linear(in_features=1024, out_features=1024, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(270987, 1024, padding_idx=2)
        )
        (pe): PositionalEncoding()
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (transformer_layers): ModuleList(
      (0-23): 24 x TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_values): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_query): Linear(in_features=1024, out_features=1024, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_values): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_query): Linear(in_features=1024, out_features=1024, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (layer_norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (generator): Linear(in_features=1024, out_features=270987, bias=True)
)
[2024-07-27 13:06:45,062 INFO] encoder: 579802112
[2024-07-27 13:06:45,062 INFO] decoder: 403393163
[2024-07-27 13:06:45,062 INFO] * number of parameters: 983195275
[2024-07-27 13:06:45,065 INFO] Trainable parameters = {'torch.float32': 983195275, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}
[2024-07-27 13:06:45,065 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}
[2024-07-27 13:06:45,065 INFO]  * src vocab size = 270987
[2024-07-27 13:06:45,065 INFO]  * tgt vocab size = 270987
[2024-07-27 13:06:45,652 INFO] Starting training on GPU: [0]
[2024-07-27 13:06:45,652 INFO] Start training loop without validation...
[2024-07-27 13:06:45,652 INFO] Scoring with: None
[2024-07-27 13:07:13,770 INFO] Step 10/10000; acc: 46.5; ppl: 139.7; xent: 4.9; lr: 0.01031; sents:    3040; bsz:  402/ 459/38; 1145/1305 tok/s;     28 sec;
[2024-07-27 13:07:32,215 INFO] Step 20/10000; acc: 47.8; ppl: 124.8; xent: 4.8; lr: 0.01969; sents:    2938; bsz:  386/ 442/37; 1674/1918 tok/s;     47 sec;
[2024-07-27 13:07:50,793 INFO] Step 30/10000; acc: 48.3; ppl: 120.6; xent: 4.8; lr: 0.02906; sents:    2970; bsz:  397/ 454/37; 1709/1955 tok/s;     65 sec;
[2024-07-27 13:08:10,218 INFO] Step 40/10000; acc: 37.7; ppl: 226.5; xent: 5.4; lr: 0.03844; sents:    1630; bsz:  578/ 632/20; 2383/2605 tok/s;     85 sec;
[2024-07-27 13:08:29,785 INFO] Step 50/10000; acc: 37.0; ppl: 247.6; xent: 5.5; lr: 0.04781; sents:    1377; bsz:  642/ 679/17; 2625/2775 tok/s;    104 sec;
[2024-07-27 13:08:49,318 INFO] Step 60/10000; acc: 37.1; ppl: 249.7; xent: 5.5; lr: 0.05719; sents:    1383; bsz:  634/ 683/17; 2599/2796 tok/s;    124 sec;
[2024-07-27 13:09:08,969 INFO] Step 70/10000; acc: 36.0; ppl: 248.9; xent: 5.5; lr: 0.06656; sents:    1356; bsz:  625/ 679/17; 2543/2763 tok/s;    143 sec;
[2024-07-27 13:09:28,326 INFO] Step 80/10000; acc: 41.1; ppl: 187.1; xent: 5.2; lr: 0.07594; sents:    2100; bsz:  570/ 605/26; 2357/2502 tok/s;    163 sec;
[2024-07-27 13:09:47,061 INFO] Step 90/10000; acc: 46.1; ppl: 140.9; xent: 4.9; lr: 0.08531; sents:    2851; bsz:  379/ 439/36; 1619/1874 tok/s;    181 sec;
[2024-07-27 13:10:05,854 INFO] Step 100/10000; acc: 47.2; ppl: 131.9; xent: 4.9; lr: 0.09328; sents:    2850; bsz:  380/ 443/36; 1616/1885 tok/s;    200 sec;
[2024-07-27 13:10:25,120 INFO] Step 110/10000; acc: 44.9; ppl: 143.7; xent: 5.0; lr: 0.08898; sents:    2635; bsz:  449/ 511/33; 1865/2123 tok/s;    219 sec;
[2024-07-27 13:10:44,867 INFO] Step 120/10000; acc: 36.5; ppl: 237.5; xent: 5.5; lr: 0.08523; sents:    1429; bsz:  600/ 644/18; 2432/2610 tok/s;    239 sec;
[2024-07-27 13:11:04,794 INFO] Step 130/10000; acc: 37.5; ppl: 243.3; xent: 5.5; lr: 0.08191; sents:    1397; bsz:  636/ 675/17; 2555/2710 tok/s;    259 sec;
[2024-07-27 13:12:10,801 INFO] Parsed 1 corpora from -data.
[2024-07-27 13:12:10,801 INFO] Loading checkpoint from /root/projects/zindi/nmt_train/models/nllb-200-600M-zindi_V3_step_1000.pt
[2024-07-27 13:12:13,657 INFO] Updating checkpoint vocabulary with new vocabulary
[2024-07-27 13:12:13,658 INFO] Get special vocabs from Transforms: {'src': ['', '', '</s>', 'dyu_Latn'], 'tgt': ['', '', 'fra_Latn']}.
[2024-07-27 13:16:01,087 INFO] Parsed 1 corpora from -data.
[2024-07-27 13:16:01,087 INFO] Loading checkpoint from /root/projects/zindi/nmt_train/models/nllb-200-600M-zindi_V3_step_1000.pt
[2024-07-27 13:16:03,956 INFO] Updating checkpoint vocabulary with new vocabulary
[2024-07-27 13:16:03,956 INFO] Get special vocabs from Transforms: {'src': ['', '', 'dyu_Latn', '</s>'], 'tgt': ['', 'fra_Latn', '']}.
[2024-07-27 13:16:04,533 INFO] The first 10 tokens of the vocabs are:['', '<s>', '<blank>', '</s>', '<unk>', 'an', '▁n', '▁m', '▁t', '▁k']
[2024-07-27 13:16:04,535 INFO] The decoder start token is: </s>
[2024-07-27 13:16:04,601 INFO] Over-ride model option set to true - use with care
[2024-07-27 13:16:04,602 INFO] Option: save_model , value: /root/projects/zindi/nmt_train/models/nllb-200-600M-zindi_V4 overriding model: /root/projects/zindi/nmt_train/models/nllb-200-600M-zindi_V3
[2024-07-27 13:16:04,602 INFO] Option: train_from , value: /root/projects/zindi/nmt_train/models/nllb-200-600M-zindi_V3_step_1000.pt overriding model: /root/projects/zindi/nmt_train/models/nllb-200-600M-zindi_V2_step_500.pt
[2024-07-27 13:16:04,602 INFO] Option: log_file , value: /root/projects/zindi/nmt_train/trainnllb-200-600M-zindi_V4.log overriding model: /root/projects/zindi/nmt_train/trainnllb-200-600M-zindi_V3.log
[2024-07-27 13:16:04,602 INFO] Building model...
[2024-07-27 13:16:13,806 INFO] Switching model to float32 for amp/apex_amp
[2024-07-27 13:16:13,806 INFO] Non quantized layer compute is fp16
[2024-07-27 13:16:13,806 INFO] Updating vocabulary embeddings with checkpoint embeddings
[2024-07-27 13:16:15,917 INFO] src: 0 new tokens
[2024-07-27 13:16:20,443 INFO] tgt: 0 new tokens
[2024-07-27 13:16:22,023 INFO] NMTModel(
  (encoder): TransformerEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(270987, 1024, padding_idx=2)
        )
        (pe): PositionalEncoding()
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer): ModuleList(
      (0-23): 24 x TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_values): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_query): Linear(in_features=1024, out_features=1024, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(270987, 1024, padding_idx=2)
        )
        (pe): PositionalEncoding()
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (transformer_layers): ModuleList(
      (0-23): 24 x TransformerDecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_values): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_query): Linear(in_features=1024, out_features=1024, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=1024, out_features=4096, bias=True)
          (w_2): Linear(in_features=4096, out_features=1024, bias=True)
          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1, inplace=False)
          (dropout_2): Dropout(p=0.1, inplace=False)
        )
        (layer_norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (context_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_values): Linear(in_features=1024, out_features=1024, bias=True)
          (linear_query): Linear(in_features=1024, out_features=1024, bias=True)
          (softmax): Softmax(dim=-1)
          (dropout): Dropout(p=0.1, inplace=False)
          (final_linear): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (layer_norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      )
    )
  )
  (generator): Linear(in_features=1024, out_features=270987, bias=True)
)
[2024-07-27 13:16:22,032 INFO] encoder: 579802112
[2024-07-27 13:16:22,032 INFO] decoder: 403393163
[2024-07-27 13:16:22,032 INFO] * number of parameters: 983195275
[2024-07-27 13:16:22,034 INFO] Trainable parameters = {'torch.float32': 983195275, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}
[2024-07-27 13:16:22,034 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}
[2024-07-27 13:16:22,034 INFO]  * src vocab size = 270987
[2024-07-27 13:16:22,034 INFO]  * tgt vocab size = 270987
[2024-07-27 13:16:22,612 INFO] Starting training on GPU: [0]
[2024-07-27 13:16:22,613 INFO] Start training loop without validation...
[2024-07-27 13:16:22,613 INFO] Scoring with: None
[2024-07-27 13:16:50,907 INFO] Step 10/10000; acc: 46.5; ppl: 139.7; xent: 4.9; lr: 0.01031; sents:    3040; bsz:  402/ 459/38; 1138/1297 tok/s;     28 sec;
[2024-07-27 13:17:09,634 INFO] Step 20/10000; acc: 47.8; ppl: 124.8; xent: 4.8; lr: 0.01969; sents:    2938; bsz:  386/ 442/37; 1649/1889 tok/s;     47 sec;
[2024-07-27 13:17:28,439 INFO] Step 30/10000; acc: 48.3; ppl: 120.6; xent: 4.8; lr: 0.02906; sents:    2970; bsz:  397/ 454/37; 1689/1931 tok/s;     66 sec;
[2024-07-27 13:17:48,056 INFO] Step 40/10000; acc: 37.7; ppl: 226.5; xent: 5.4; lr: 0.03844; sents:    1630; bsz:  578/ 632/20; 2359/2579 tok/s;     85 sec;
[2024-07-27 13:18:07,860 INFO] Step 50/10000; acc: 37.0; ppl: 247.6; xent: 5.5; lr: 0.04781; sents:    1377; bsz:  642/ 679/17; 2594/2742 tok/s;    105 sec;
[2024-07-27 13:18:27,658 INFO] Step 60/10000; acc: 37.1; ppl: 249.7; xent: 5.5; lr: 0.05719; sents:    1383; bsz:  634/ 683/17; 2564/2758 tok/s;    125 sec;
[2024-07-27 13:18:47,499 INFO] Step 70/10000; acc: 36.0; ppl: 248.9; xent: 5.5; lr: 0.06656; sents:    1356; bsz:  625/ 679/17; 2518/2736 tok/s;    145 sec;
[2024-07-27 13:19:07,093 INFO] Step 80/10000; acc: 41.1; ppl: 187.1; xent: 5.2; lr: 0.07594; sents:    2100; bsz:  570/ 605/26; 2329/2472 tok/s;    164 sec;
[2024-07-27 13:19:26,046 INFO] Step 90/10000; acc: 46.1; ppl: 140.9; xent: 4.9; lr: 0.08531; sents:    2851; bsz:  379/ 439/36; 1600/1852 tok/s;    183 sec;
[2024-07-27 13:19:45,101 INFO] Step 100/10000; acc: 47.2; ppl: 131.9; xent: 4.9; lr: 0.09328; sents:    2850; bsz:  380/ 443/36; 1593/1859 tok/s;    202 sec;
[2024-07-27 13:20:04,404 INFO] Step 110/10000; acc: 44.9; ppl: 143.7; xent: 5.0; lr: 0.08898; sents:    2635; bsz:  449/ 511/33; 1862/2119 tok/s;    222 sec;
[2024-07-27 13:20:24,188 INFO] Step 120/10000; acc: 36.5; ppl: 237.5; xent: 5.5; lr: 0.08523; sents:    1429; bsz:  600/ 644/18; 2428/2605 tok/s;    242 sec;
[2024-07-27 13:20:44,216 INFO] Step 130/10000; acc: 37.5; ppl: 243.3; xent: 5.5; lr: 0.08191; sents:    1397; bsz:  636/ 675/17; 2542/2697 tok/s;    262 sec;
[2024-07-27 13:21:04,183 INFO] Step 140/10000; acc: 37.1; ppl: 240.9; xent: 5.5; lr: 0.07895; sents:    1370; bsz:  629/ 679/17; 2521/2719 tok/s;    282 sec;
[2024-07-27 13:21:24,039 INFO] Step 150/10000; acc: 37.1; ppl: 234.3; xent: 5.5; lr: 0.07629; sents:    1378; bsz:  631/ 674/17; 2543/2714 tok/s;    301 sec;
[2024-07-27 13:21:43,364 INFO] Step 160/10000; acc: 43.9; ppl: 158.4; xent: 5.1; lr: 0.07389; sents:    2597; bsz:  482/ 537/32; 1996/2225 tok/s;    321 sec;
[2024-07-27 13:22:02,257 INFO] Step 170/10000; acc: 46.9; ppl: 130.6; xent: 4.9; lr: 0.07169; sents:    2851; bsz:  393/ 447/36; 1665/1893 tok/s;    340 sec;
[2024-07-27 13:22:21,189 INFO] Step 180/10000; acc: 48.0; ppl: 120.6; xent: 4.8; lr: 0.06968; sents:    2927; bsz:  384/ 447/37; 1622/1890 tok/s;    359 sec;
[2024-07-27 13:22:40,730 INFO] Step 190/10000; acc: 41.5; ppl: 177.4; xent: 5.2; lr: 0.06784; sents:    2191; bsz:  502/ 562/27; 2054/2302 tok/s;    378 sec;
[2024-07-27 13:23:00,621 INFO] Step 200/10000; acc: 36.9; ppl: 238.9; xent: 5.5; lr: 0.06613; sents:    1348; bsz:  627/ 671/17; 2523/2698 tok/s;    398 sec;
[2024-07-27 13:23:20,541 INFO] Step 210/10000; acc: 37.9; ppl: 231.3; xent: 5.4; lr: 0.06454; sents:    1342; bsz:  635/ 670/17; 2550/2689 tok/s;    418 sec;
[2024-07-27 13:23:40,465 INFO] Step 220/10000; acc: 36.8; ppl: 237.3; xent: 5.5; lr: 0.06306; sents:    1368; bsz:  641/ 693/17; 2574/2783 tok/s;    438 sec;
[2024-07-27 13:24:00,254 INFO] Step 230/10000; acc: 38.9; ppl: 209.0; xent: 5.3; lr: 0.06168; sents:    1573; bsz:  594/ 641/20; 2403/2593 tok/s;    458 sec;
[2024-07-27 13:24:19,511 INFO] Step 240/10000; acc: 45.0; ppl: 150.8; xent: 5.0; lr: 0.06039; sents:    2811; bsz:  434/ 485/35; 1803/2013 tok/s;    477 sec;
[2024-07-27 13:24:38,513 INFO] Step 250/10000; acc: 48.2; ppl: 115.9; xent: 4.8; lr: 0.05917; sents:    2920; bsz:  382/ 441/36; 1609/1855 tok/s;    496 sec;
[2024-07-27 13:24:57,477 INFO] Step 260/10000; acc: 47.2; ppl: 124.5; xent: 4.8; lr: 0.05803; sents:    2775; bsz:  391/ 450/35; 1651/1897 tok/s;    515 sec;
[2024-07-27 13:25:17,103 INFO] Step 270/10000; acc: 39.3; ppl: 197.4; xent: 5.3; lr: 0.05695; sents:    1787; bsz:  552/ 610/22; 2250/2487 tok/s;    534 sec;
[2024-07-27 13:25:37,032 INFO] Step 280/10000; acc: 37.4; ppl: 233.8; xent: 5.5; lr: 0.05593; sents:    1397; bsz:  634/ 677/17; 2545/2716 tok/s;    554 sec;
[2024-07-27 13:25:56,936 INFO] Step 290/10000; acc: 37.9; ppl: 225.4; xent: 5.4; lr: 0.05496; sents:    1350; bsz:  645/ 681/17; 2594/2735 tok/s;    574 sec;
[2024-07-27 13:26:16,766 INFO] Step 300/10000; acc: 37.4; ppl: 224.5; xent: 5.4; lr: 0.05404; sents:    1385; bsz:  617/ 670/17; 2489/2702 tok/s;    594 sec;
[2024-07-27 13:26:36,425 INFO] Step 310/10000; acc: 40.8; ppl: 186.5; xent: 5.2; lr: 0.05316; sents:    1974; bsz:  562/ 604/25; 2289/2458 tok/s;    614 sec;
[2024-07-27 13:26:55,495 INFO] Step 320/10000; acc: 47.2; ppl: 128.1; xent: 4.9; lr: 0.05233; sents:    2908; bsz:  406/ 461/36; 1704/1936 tok/s;    633 sec;
[2024-07-27 13:27:14,381 INFO] Step 330/10000; acc: 47.3; ppl: 125.5; xent: 4.8; lr: 0.05153; sents:    2791; bsz:  370/ 433/35; 1566/1835 tok/s;    652 sec;
[2024-07-27 13:27:33,527 INFO] Step 340/10000; acc: 45.8; ppl: 133.9; xent: 4.9; lr: 0.05077; sents:    2712; bsz:  444/ 503/34; 1856/2102 tok/s;    671 sec;
[2024-07-27 13:27:52,980 INFO] Step 350/10000; acc: 38.3; ppl: 212.7; xent: 5.4; lr: 0.05004; sents:    1476; bsz:  599/ 650/18; 2462/2674 tok/s;    690 sec;
[2024-07-27 13:28:12,471 INFO] Step 360/10000; acc: 37.5; ppl: 233.3; xent: 5.5; lr: 0.04934; sents:    1392; bsz:  641/ 678/17; 2630/2784 tok/s;    710 sec;
[2024-07-27 13:28:32,030 INFO] Step 370/10000; acc: 37.8; ppl: 223.7; xent: 5.4; lr: 0.04867; sents:    1363; bsz:  635/ 682/17; 2596/2788 tok/s;    729 sec;
[2024-07-27 13:28:51,604 INFO] Step 380/10000; acc: 37.3; ppl: 223.6; xent: 5.4; lr: 0.04803; sents:    1368; bsz:  637/ 686/17; 2602/2803 tok/s;    749 sec;
[2024-07-27 13:29:10,600 INFO] Step 390/10000; acc: 44.1; ppl: 156.2; xent: 5.1; lr: 0.04741; sents:    2571; bsz:  493/ 549/32; 2076/2310 tok/s;    768 sec;
[2024-07-27 13:29:29,253 INFO] Step 400/10000; acc: 47.7; ppl: 119.4; xent: 4.8; lr: 0.04682; sents:    2904; bsz:  403/ 450/36; 1728/1932 tok/s;    787 sec;
[2024-07-27 13:29:47,752 INFO] Step 410/10000; acc: 47.8; ppl: 118.6; xent: 4.8; lr: 0.04624; sents:    2851; bsz:  379/ 439/36; 1637/1899 tok/s;    805 sec;
[2024-07-27 13:30:06,879 INFO] Step 420/10000; acc: 42.2; ppl: 165.6; xent: 5.1; lr: 0.04569; sents:    2224; bsz:  497/ 557/28; 2077/2330 tok/s;    824 sec;
[2024-07-27 13:30:26,353 INFO] Step 430/10000; acc: 37.8; ppl: 218.5; xent: 5.4; lr: 0.04516; sents:    1385; bsz:  627/ 672/17; 2577/2759 tok/s;    844 sec;
[2024-07-27 13:30:45,858 INFO] Step 440/10000; acc: 38.1; ppl: 218.9; xent: 5.4; lr: 0.04464; sents:    1386; bsz:  635/ 677/17; 2605/2776 tok/s;    863 sec;
[2024-07-27 13:31:05,473 INFO] Step 450/10000; acc: 37.3; ppl: 222.1; xent: 5.4; lr: 0.04415; sents:    1355; bsz:  636/ 686/17; 2596/2797 tok/s;    883 sec;
[2024-07-27 13:31:24,849 INFO] Step 460/10000; acc: 39.6; ppl: 194.4; xent: 5.3; lr: 0.04366; sents:    1689; bsz:  599/ 645/21; 2472/2664 tok/s;    902 sec;
[2024-07-27 13:31:43,600 INFO] Step 470/10000; acc: 45.9; ppl: 136.7; xent: 4.9; lr: 0.04320; sents:    2712; bsz:  432/ 480/34; 1841/2049 tok/s;    921 sec;
[2024-07-27 13:32:02,126 INFO] Step 480/10000; acc: 47.3; ppl: 124.4; xent: 4.8; lr: 0.04275; sents:    2799; bsz:  374/ 433/35; 1615/1872 tok/s;    940 sec;
[2024-07-27 13:32:20,841 INFO] Step 490/10000; acc: 47.2; ppl: 118.8; xent: 4.8; lr: 0.04231; sents:    2804; bsz:  412/ 470/35; 1762/2008 tok/s;    958 sec;
[2024-07-27 13:32:40,122 INFO] Step 500/10000; acc: 40.2; ppl: 184.5; xent: 5.2; lr: 0.04188; sents:    1855; bsz:  540/ 597/23; 2242/2475 tok/s;    978 sec;
[2024-07-27 13:32:59,751 INFO] Step 510/10000; acc: 37.8; ppl: 221.0; xent: 5.4; lr: 0.04147; sents:    1377; bsz:  644/ 689/17; 2624/2806 tok/s;    997 sec;
[2024-07-27 13:33:19,389 INFO] Step 520/10000; acc: 38.3; ppl: 214.7; xent: 5.4; lr: 0.04107; sents:    1383; bsz:  637/ 677/17; 2594/2759 tok/s;   1017 sec;
[2024-07-27 13:33:39,384 INFO] Step 530/10000; acc: 37.5; ppl: 215.3; xent: 5.4; lr: 0.04068; sents:    1341; bsz:  630/ 675/17; 2519/2702 tok/s;   1037 sec;
[2024-07-27 13:33:58,885 INFO] Step 540/10000; acc: 41.5; ppl: 175.2; xent: 5.2; lr: 0.04031; sents:    2028; bsz:  544/ 591/25; 2231/2425 tok/s;   1056 sec;
[2024-07-27 13:34:17,943 INFO] Step 550/10000; acc: 46.6; ppl: 127.1; xent: 4.8; lr: 0.03994; sents:    2803; bsz:  415/ 465/35; 1742/1951 tok/s;   1075 sec;
[2024-07-27 13:34:36,838 INFO] Step 560/10000; acc: 47.8; ppl: 120.9; xent: 4.8; lr: 0.03958; sents:    2872; bsz:  379/ 441/36; 1603/1868 tok/s;   1094 sec;
[2024-07-27 13:34:55,931 INFO] Step 570/10000; acc: 45.3; ppl: 134.7; xent: 4.9; lr: 0.03923; sents:    2496; bsz:  425/ 487/31; 1780/2039 tok/s;   1113 sec;
[2024-07-27 13:35:15,749 INFO] Step 580/10000; acc: 39.3; ppl: 192.2; xent: 5.3; lr: 0.03889; sents:    1677; bsz:  590/ 641/21; 2381/2586 tok/s;   1133 sec;
[2024-07-27 13:35:35,563 INFO] Step 590/10000; acc: 38.1; ppl: 219.1; xent: 5.4; lr: 0.03856; sents:    1322; bsz:  619/ 662/17; 2498/2673 tok/s;   1153 sec;
[2024-07-27 13:35:55,480 INFO] Step 600/10000; acc: 38.3; ppl: 208.4; xent: 5.3; lr: 0.03824; sents:    1396; bsz:  634/ 680/17; 2546/2732 tok/s;   1173 sec;
[2024-07-27 13:36:15,321 INFO] Step 610/10000; acc: 38.7; ppl: 203.6; xent: 5.3; lr: 0.03793; sents:    1495; bsz:  614/ 657/19; 2477/2648 tok/s;   1193 sec;
[2024-07-27 13:36:34,832 INFO] Step 620/10000; acc: 42.2; ppl: 168.3; xent: 5.1; lr: 0.03762; sents:    2196; bsz:  518/ 566/27; 2126/2323 tok/s;   1212 sec;
[2024-07-27 13:36:53,867 INFO] Step 630/10000; acc: 47.5; ppl: 121.7; xent: 4.8; lr: 0.03732; sents:    2891; bsz:  397/ 453/36; 1669/1906 tok/s;   1231 sec;
[2024-07-27 13:37:12,794 INFO] Step 640/10000; acc: 48.4; ppl: 111.7; xent: 4.7; lr: 0.03703; sents:    2874; bsz:  384/ 441/36; 1622/1865 tok/s;   1250 sec;
[2024-07-27 13:37:32,128 INFO] Step 650/10000; acc: 42.9; ppl: 154.8; xent: 5.0; lr: 0.03674; sents:    2215; bsz:  469/ 532/28; 1939/2203 tok/s;   1270 sec;
[2024-07-27 13:37:51,998 INFO] Step 660/10000; acc: 38.8; ppl: 198.7; xent: 5.3; lr: 0.03646; sents:    1519; bsz:  613/ 658/19; 2469/2648 tok/s;   1289 sec;
[2024-07-27 13:38:11,935 INFO] Step 670/10000; acc: 38.3; ppl: 215.7; xent: 5.4; lr: 0.03619; sents:    1382; bsz:  635/ 678/17; 2549/2721 tok/s;   1309 sec;
[2024-07-27 13:38:31,875 INFO] Step 680/10000; acc: 38.4; ppl: 207.5; xent: 5.3; lr: 0.03593; sents:    1378; bsz:  626/ 674/17; 2511/2704 tok/s;   1329 sec;
[2024-07-27 13:38:51,589 INFO] Step 690/10000; acc: 39.5; ppl: 191.8; xent: 5.3; lr: 0.03566; sents:    1703; bsz:  584/ 627/21; 2370/2546 tok/s;   1349 sec;
[2024-07-27 13:39:10,963 INFO] Step 700/10000; acc: 44.2; ppl: 148.9; xent: 5.0; lr: 0.03541; sents:    2465; bsz:  496/ 542/31; 2048/2237 tok/s;   1368 sec;
[2024-07-27 13:39:29,888 INFO] Step 710/10000; acc: 47.7; ppl: 120.7; xent: 4.8; lr: 0.03516; sents:    2835; bsz:  381/ 440/35; 1612/1862 tok/s;   1387 sec;
[2024-07-27 13:39:48,897 INFO] Step 720/10000; acc: 47.3; ppl: 120.8; xent: 4.8; lr: 0.03491; sents:    2735; bsz:  400/ 463/34; 1684/1948 tok/s;   1406 sec;
[2024-07-27 13:40:08,516 INFO] Step 730/10000; acc: 41.9; ppl: 161.8; xent: 5.1; lr: 0.03467; sents:    2074; bsz:  526/ 582/26; 2145/2372 tok/s;   1426 sec;
[2024-07-27 13:40:28,377 INFO] Step 740/10000; acc: 38.4; ppl: 207.7; xent: 5.3; lr: 0.03444; sents:    1430; bsz:  624/ 670/18; 2515/2698 tok/s;   1446 sec;
[2024-07-27 13:40:48,288 INFO] Step 750/10000; acc: 38.7; ppl: 204.3; xent: 5.3; lr: 0.03421; sents:    1398; bsz:  636/ 682/17; 2556/2739 tok/s;   1466 sec;
[2024-07-27 13:41:08,274 INFO] Step 760/10000; acc: 38.1; ppl: 206.0; xent: 5.3; lr: 0.03398; sents:    1381; bsz:  639/ 686/17; 2560/2746 tok/s;   1486 sec;
[2024-07-27 13:41:27,817 INFO] Step 770/10000; acc: 40.7; ppl: 178.1; xent: 5.2; lr: 0.03376; sents:    1999; bsz:  556/ 601/25; 2278/2460 tok/s;   1505 sec;
[2024-07-27 13:41:46,601 INFO] Step 780/10000; acc: 46.9; ppl: 126.6; xent: 4.8; lr: 0.03355; sents:    2730; bsz:  441/ 497/34; 1880/2118 tok/s;   1524 sec;
[2024-07-27 13:42:05,567 INFO] Step 790/10000; acc: 48.0; ppl: 116.4; xent: 4.8; lr: 0.03333; sents:    2972; bsz:  403/ 457/37; 1699/1929 tok/s;   1543 sec;
[2024-07-27 13:42:24,867 INFO] Step 800/10000; acc: 44.1; ppl: 141.7; xent: 5.0; lr: 0.03312; sents:    2365; bsz:  448/ 509/30; 1856/2108 tok/s;   1562 sec;
[2024-07-27 13:42:44,473 INFO] Step 810/10000; acc: 40.5; ppl: 175.5; xent: 5.2; lr: 0.03292; sents:    1819; bsz:  555/ 607/23; 2263/2477 tok/s;   1582 sec;
[2024-07-27 13:43:04,214 INFO] Step 820/10000; acc: 38.5; ppl: 204.6; xent: 5.3; lr: 0.03272; sents:    1364; bsz:  621/ 662/17; 2515/2684 tok/s;   1602 sec;
[2024-07-27 13:43:24,208 INFO] Step 830/10000; acc: 38.6; ppl: 199.1; xent: 5.3; lr: 0.03252; sents:    1400; bsz:  646/ 691/18; 2584/2766 tok/s;   1622 sec;
[2024-07-27 13:43:44,116 INFO] Step 840/10000; acc: 39.6; ppl: 189.5; xent: 5.2; lr: 0.03233; sents:    1671; bsz:  603/ 653/21; 2424/2626 tok/s;   1642 sec;
[2024-07-27 13:44:03,649 INFO] Step 850/10000; acc: 42.3; ppl: 163.1; xent: 5.1; lr: 0.03214; sents:    2185; bsz:  514/ 563/27; 2103/2307 tok/s;   1661 sec;
[2024-07-27 13:44:22,771 INFO] Step 860/10000; acc: 46.9; ppl: 125.3; xent: 4.8; lr: 0.03195; sents:    2754; bsz:  414/ 467/34; 1733/1953 tok/s;   1680 sec;
[2024-07-27 13:44:41,887 INFO] Step 870/10000; acc: 47.0; ppl: 120.0; xent: 4.8; lr: 0.03177; sents:    2764; bsz:  407/ 463/35; 1702/1936 tok/s;   1699 sec;
[2024-07-27 13:45:01,331 INFO] Step 880/10000; acc: 43.4; ppl: 150.8; xent: 5.0; lr: 0.03159; sents:    2217; bsz:  482/ 537/28; 1982/2211 tok/s;   1719 sec;
[2024-07-27 13:45:21,128 INFO] Step 890/10000; acc: 39.9; ppl: 183.2; xent: 5.2; lr: 0.03141; sents:    1680; bsz:  586/ 642/21; 2370/2594 tok/s;   1739 sec;
[2024-07-27 13:45:40,997 INFO] Step 900/10000; acc: 38.5; ppl: 202.6; xent: 5.3; lr: 0.03123; sents:    1366; bsz:  644/ 682/17; 2591/2745 tok/s;   1758 sec;
[2024-07-27 13:46:00,934 INFO] Step 910/10000; acc: 38.4; ppl: 201.4; xent: 5.3; lr: 0.03106; sents:    1369; bsz:  643/ 685/17; 2579/2747 tok/s;   1778 sec;
[2024-07-27 13:46:20,457 INFO] Step 920/10000; acc: 40.6; ppl: 177.4; xent: 5.2; lr: 0.03089; sents:    1855; bsz:  557/ 610/23; 2284/2501 tok/s;   1798 sec;
[2024-07-27 13:46:39,745 INFO] Step 930/10000; acc: 44.4; ppl: 141.3; xent: 5.0; lr: 0.03073; sents:    2389; bsz:  482/ 531/30; 1999/2203 tok/s;   1817 sec;
[2024-07-27 13:46:58,682 INFO] Step 940/10000; acc: 47.2; ppl: 123.9; xent: 4.8; lr: 0.03056; sents:    2826; bsz:  399/ 458/35; 1687/1936 tok/s;   1836 sec;
[2024-07-27 13:47:17,697 INFO] Step 950/10000; acc: 45.2; ppl: 131.8; xent: 4.9; lr: 0.03040; sents:    2487; bsz:  426/ 481/31; 1790/2023 tok/s;   1855 sec;
[2024-07-27 13:47:37,107 INFO] Step 960/10000; acc: 42.3; ppl: 158.5; xent: 5.1; lr: 0.03024; sents:    2023; bsz:  513/ 566/25; 2114/2331 tok/s;   1874 sec;
[2024-07-27 13:47:56,763 INFO] Step 970/10000; acc: 39.5; ppl: 189.7; xent: 5.2; lr: 0.03009; sents:    1593; bsz:  577/ 629/20; 2350/2560 tok/s;   1894 sec;
[2024-07-27 13:48:16,713 INFO] Step 980/10000; acc: 38.8; ppl: 199.3; xent: 5.3; lr: 0.02993; sents:    1379; bsz:  642/ 681/17; 2575/2729 tok/s;   1914 sec;
[2024-07-27 13:48:36,582 INFO] Step 990/10000; acc: 38.9; ppl: 189.9; xent: 5.2; lr: 0.02978; sents:    1444; bsz:  623/ 665/18; 2509/2679 tok/s;   1934 sec;
[2024-07-27 13:48:56,207 INFO] Step 1000/10000; acc: 42.0; ppl: 166.5; xent: 5.1; lr: 0.02963; sents:    2135; bsz:  539/ 596/27; 2195/2428 tok/s;   1954 sec;
[2024-07-27 13:48:56,286 INFO] Saving checkpoint /root/projects/zindi/nmt_train/models/nllb-200-600M-zindi_V4_step_1000.pt
[2024-07-27 13:49:21,007 INFO] Step 1010/10000; acc: 45.2; ppl: 135.5; xent: 4.9; lr: 0.02948; sents:    2458; bsz:  474/ 524/31; 1530/1689 tok/s;   1978 sec;
[2024-07-27 13:49:39,980 INFO] Step 1020/10000; acc: 47.8; ppl: 117.8; xent: 4.8; lr: 0.02934; sents:    2800; bsz:  391/ 450/35; 1650/1897 tok/s;   1997 sec;
[2024-07-27 13:49:59,241 INFO] Step 1030/10000; acc: 43.2; ppl: 148.7; xent: 5.0; lr: 0.02920; sents:    2308; bsz:  474/ 529/29; 1968/2199 tok/s;   2017 sec;
[2024-07-27 13:50:18,701 INFO] Step 1040/10000; acc: 41.9; ppl: 161.0; xent: 5.1; lr: 0.02906; sents:    1986; bsz:  524/ 574/25; 2154/2361 tok/s;   2036 sec;
[2024-07-27 13:50:38,445 INFO] Step 1050/10000; acc: 38.9; ppl: 191.8; xent: 5.3; lr: 0.02892; sents:    1481; bsz:  603/ 657/19; 2444/2662 tok/s;   2056 sec;
[2024-07-27 13:50:58,419 INFO] Step 1060/10000; acc: 38.9; ppl: 195.8; xent: 5.3; lr: 0.02878; sents:    1343; bsz:  647/ 684/17; 2593/2738 tok/s;   2076 sec;
[2024-07-27 13:51:18,255 INFO] Step 1070/10000; acc: 40.2; ppl: 178.8; xent: 5.2; lr: 0.02865; sents:    1724; bsz:  589/ 635/22; 2377/2561 tok/s;   2096 sec;
[2024-07-27 13:51:37,705 INFO] Step 1080/10000; acc: 42.6; ppl: 158.5; xent: 5.1; lr: 0.02851; sents:    2211; bsz:  517/ 565/28; 2127/2323 tok/s;   2115 sec;
[2024-07-27 13:51:56,847 INFO] Step 1090/10000; acc: 45.2; ppl: 135.8; xent: 4.9; lr: 0.02838; sents:    2575; bsz:  457/ 516/32; 1909/2155 tok/s;   2134 sec;
[2024-07-27 13:52:15,839 INFO] Step 1100/10000; acc: 47.0; ppl: 120.5; xent: 4.8; lr: 0.02825; sents:    2761; bsz:  411/ 470/35; 1731/1982 tok/s;   2153 sec;
[2024-07-27 13:52:35,209 INFO] Step 1110/10000; acc: 42.2; ppl: 157.8; xent: 5.1; lr: 0.02813; sents:    2061; bsz:  498/ 552/26; 2055/2282 tok/s;   2173 sec;
[2024-07-27 13:52:54,762 INFO] Step 1120/10000; acc: 41.7; ppl: 162.2; xent: 5.1; lr: 0.02800; sents:    1986; bsz:  553/ 606/25; 2263/2481 tok/s;   2192 sec;
[2024-07-27 13:53:14,534 INFO] Step 1130/10000; acc: 38.7; ppl: 192.0; xent: 5.3; lr: 0.02788; sents:    1365; bsz:  614/ 661/17; 2485/2677 tok/s;   2212 sec;
[2024-07-27 13:53:34,461 INFO] Step 1140/10000; acc: 38.5; ppl: 196.1; xent: 5.3; lr: 0.02775; sents:    1395; bsz:  648/ 692/17; 2600/2779 tok/s;   2232 sec;
[2024-07-27 13:53:54,189 INFO] Step 1150/10000; acc: 41.7; ppl: 169.0; xent: 5.1; lr: 0.02763; sents:    2104; bsz:  562/ 609/26; 2278/2472 tok/s;   2252 sec;
[2024-07-27 13:54:13,683 INFO] Step 1160/10000; acc: 43.5; ppl: 147.5; xent: 5.0; lr: 0.02751; sents:    2209; bsz:  518/ 562/28; 2128/2305 tok/s;   2271 sec;
[2024-07-27 13:54:32,749 INFO] Step 1170/10000; acc: 46.6; ppl: 124.4; xent: 4.8; lr: 0.02740; sents:    2773; bsz:  417/ 479/35; 1751/2010 tok/s;   2290 sec;
[2024-07-27 13:54:52,074 INFO] Step 1180/10000; acc: 43.9; ppl: 141.5; xent: 5.0; lr: 0.02728; sents:    2342; bsz:  462/ 520/29; 1912/2154 tok/s;   2309 sec;
[2024-07-27 13:55:11,483 INFO] Step 1190/10000; acc: 42.7; ppl: 151.0; xent: 5.0; lr: 0.02717; sents:    2072; bsz:  499/ 548/26; 2056/2257 tok/s;   2329 sec;
[2024-07-27 13:55:31,146 INFO] Step 1200/10000; acc: 40.9; ppl: 173.1; xent: 5.2; lr: 0.02705; sents:    1759; bsz:  581/ 632/22; 2362/2573 tok/s;   2349 sec;
[2024-07-27 13:55:50,962 INFO] Step 1210/10000; acc: 38.7; ppl: 190.6; xent: 5.3; lr: 0.02694; sents:    1368; bsz:  613/ 657/17; 2476/2652 tok/s;   2368 sec;
[2024-07-27 13:56:10,958 INFO] Step 1220/10000; acc: 40.0; ppl: 177.8; xent: 5.2; lr: 0.02683; sents:    1725; bsz:  634/ 679/22; 2537/2717 tok/s;   2388 sec;
[2024-07-27 13:56:30,358 INFO] Step 1230/10000; acc: 42.1; ppl: 160.5; xent: 5.1; lr: 0.02672; sents:    2128; bsz:  504/ 554/27; 2077/2284 tok/s;   2408 sec;
[2024-07-27 13:56:49,641 INFO] Step 1240/10000; acc: 43.5; ppl: 148.7; xent: 5.0; lr: 0.02661; sents:    2234; bsz:  485/ 533/28; 2013/2212 tok/s;   2427 sec;
[2024-07-27 13:57:08,793 INFO] Step 1250/10000; acc: 46.9; ppl: 118.4; xent: 4.8; lr: 0.02651; sents:    2755; bsz:  434/ 493/34; 1811/2058 tok/s;   2446 sec;
[2024-07-27 13:57:28,179 INFO] Step 1260/10000; acc: 42.6; ppl: 155.0; xent: 5.0; lr: 0.02640; sents:    2137; bsz:  487/ 544/27; 2009/2245 tok/s;   2466 sec;
[2024-07-27 13:57:47,645 INFO] Step 1270/10000; acc: 42.3; ppl: 156.2; xent: 5.1; lr: 0.02630; sents:    2051; bsz:  523/ 582/26; 2150/2391 tok/s;   2485 sec;
[2024-07-27 13:58:07,499 INFO] Step 1280/10000; acc: 40.1; ppl: 176.6; xent: 5.2; lr: 0.02619; sents:    1659; bsz:  607/ 652/21; 2444/2626 tok/s;   2505 sec;
[2024-07-27 13:58:27,364 INFO] Step 1290/10000; acc: 39.0; ppl: 189.8; xent: 5.2; lr: 0.02609; sents:    1358; bsz:  626/ 661/17; 2522/2661 tok/s;   2525 sec;
[2024-07-27 13:58:47,041 INFO] Step 1300/10000; acc: 41.2; ppl: 169.5; xent: 5.1; lr: 0.02599; sents:    1903; bsz:  568/ 615/24; 2311/2499 tok/s;   2544 sec;
[2024-07-27 13:59:06,536 INFO] Step 1310/10000; acc: 42.5; ppl: 152.7; xent: 5.0; lr: 0.02589; sents:    2094; bsz:  497/ 553/26; 2039/2269 tok/s;   2564 sec;
[2024-07-27 13:59:25,836 INFO] Step 1320/10000; acc: 45.3; ppl: 133.9; xent: 4.9; lr: 0.02579; sents:    2484; bsz:  462/ 512/31; 1914/2124 tok/s;   2583 sec;
[2024-07-27 13:59:45,073 INFO] Step 1330/10000; acc: 44.7; ppl: 136.0; xent: 4.9; lr: 0.02570; sents:    2454; bsz:  450/ 508/31; 1873/2113 tok/s;   2602 sec;
[2024-07-27 14:00:04,657 INFO] Step 1340/10000; acc: 42.7; ppl: 149.7; xent: 5.0; lr: 0.02560; sents:    2112; bsz:  500/ 559/26; 2044/2283 tok/s;   2622 sec;
