{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/projects/zindi/nmt_train/models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-27 11:00:29,194 INFO] Parsed 1 corpora from -data.\n",
      "[2024-07-27 11:00:29,194 INFO] Loading checkpoint from /root/projects/zindi/nmt_train/models/nllb-200-600M-onmt.pt\n",
      "[2024-07-27 11:00:31,012 WARNING] configured transforms is different from checkpoint: +{'prefix', 'suffix', 'sentencepiece'}\n",
      "[2024-07-27 11:00:31,013 INFO] Get special vocabs from Transforms: {'src': ['', 'dyu_Latn', '', '</s>'], 'tgt': ['', 'fra_Latn', '']}.\n",
      "[2024-07-27 11:00:31,578 INFO] The first 10 tokens of the vocabs are:['', '<s>', '<blank>', '</s>', '<unk>', 'an', '▁n', '▁m', '▁t', '▁k']\n",
      "[2024-07-27 11:00:31,580 INFO] The decoder start token is: </s>\n",
      "[2024-07-27 11:00:31,621 INFO] Updating checkpoint vocabulary with new vocabulary\n",
      "[2024-07-27 11:00:31,623 INFO] Get special vocabs from Transforms: {'src': ['', 'dyu_Latn', '', '</s>'], 'tgt': ['', 'fra_Latn', '']}.\n",
      "[2024-07-27 11:00:32,261 INFO] The first 10 tokens of the vocabs are:['', '<s>', '<blank>', '</s>', '<unk>', 'an', '▁n', '▁m', '▁t', '▁k']\n",
      "[2024-07-27 11:00:32,263 INFO] The decoder start token is: </s>\n",
      "[2024-07-27 11:00:32,340 INFO] Over-ride model option set to true - use with care\n",
      "[2024-07-27 11:00:32,341 INFO] Option: config , value: config2.yaml overriding model: \n",
      "[2024-07-27 11:00:32,341 INFO] Option: data , value: {'corpus_1': {'path_src': '/root/projects/zindi/nmt_train/data/all_dyu.txt', 'path_tgt': '/root/projects/zindi/nmt_train/data/all_fr.txt', 'transforms': ['sentencepiece', 'prefix', 'suffix', 'filtertoolong'], 'weight': 10, 'src_prefix': 'dyu_Latn', 'tgt_prefix': 'fra_Latn', 'src_suffix': '</s>', 'tgt_suffix': '', 'path_align': None}} overriding model: {}\n",
      "[2024-07-27 11:00:32,341 INFO] Option: skip_empty_level , value: warning overriding model: silent\n",
      "[2024-07-27 11:00:32,341 INFO] Option: save_data , value: /root/projects/zindi/nmt_train/train overriding model: \n",
      "[2024-07-27 11:00:32,341 INFO] Option: src_vocab , value: /root/projects/zindi/nmt_train/models/dictionary2.txt overriding model: \n",
      "[2024-07-27 11:00:32,341 INFO] Option: tgt_vocab , value: /root/projects/zindi/nmt_train/models/dictionary2.txt overriding model: \n",
      "[2024-07-27 11:00:32,341 INFO] Option: src_vocab_size , value: 270987 overriding model: 256206\n",
      "[2024-07-27 11:00:32,341 INFO] Option: tgt_vocab_size , value: 270987 overriding model: 256206\n",
      "[2024-07-27 11:00:32,341 INFO] Option: src_seq_length , value: 120 overriding model: 150\n",
      "[2024-07-27 11:00:32,341 INFO] Option: tgt_seq_length , value: 192 overriding model: 150\n",
      "[2024-07-27 11:00:32,341 INFO] Option: src_subword_model , value: /root/projects/zindi/nmt_train/models/flores200_sacrebleu_tokenizer_spm2.model overriding model: \n",
      "[2024-07-27 11:00:32,341 INFO] Option: tgt_subword_model , value: /root/projects/zindi/nmt_train/models/flores200_sacrebleu_tokenizer_spm2.model overriding model: \n",
      "[2024-07-27 11:00:32,341 INFO] Option: update_vocab , value: True overriding model: False\n",
      "[2024-07-27 11:00:32,341 INFO] Option: enc_layers , value: 24 overriding model: 12\n",
      "[2024-07-27 11:00:32,341 INFO] Option: dec_layers , value: 24 overriding model: 12\n",
      "[2024-07-27 11:00:32,341 INFO] Option: self_attn_type , value: scaled-dot-flash overriding model: scaled-dot\n",
      "[2024-07-27 11:00:32,341 INFO] Option: bucket_size , value: 65536 overriding model: 262144\n",
      "[2024-07-27 11:00:32,341 INFO] Option: prefetch_factor , value: 2 overriding model: 400\n",
      "[2024-07-27 11:00:32,341 INFO] Option: save_model , value: /root/projects/zindi/nmt_train/models/nllb-200-600M-zindi_V2 overriding model: nllb\n",
      "[2024-07-27 11:00:32,342 INFO] Option: save_checkpoint_steps , value: 500 overriding model: 5000\n",
      "[2024-07-27 11:00:32,342 INFO] Option: keep_checkpoint , value: 3 overriding model: 50\n",
      "[2024-07-27 11:00:32,342 INFO] Option: train_from , value: /root/projects/zindi/nmt_train/models/nllb-200-600M-onmt.pt overriding model: \n",
      "[2024-07-27 11:00:32,342 INFO] Option: reset_optim , value: all overriding model: none\n",
      "[2024-07-27 11:00:32,342 INFO] Option: num_workers , value: 8 overriding model: 4\n",
      "[2024-07-27 11:00:32,342 INFO] Option: batch_size , value: 32 overriding model: 8192\n",
      "[2024-07-27 11:00:32,342 INFO] Option: accum_count , value: [8, 8, 8] overriding model: [4]\n",
      "[2024-07-27 11:00:32,342 INFO] Option: accum_steps , value: [0, 15000, 30000] overriding model: [0]\n",
      "[2024-07-27 11:00:32,342 INFO] Option: valid_steps , value: 10000 overriding model: 5000\n",
      "[2024-07-27 11:00:32,342 INFO] Option: valid_batch_size , value: 32 overriding model: 4096\n",
      "[2024-07-27 11:00:32,342 INFO] Option: train_steps , value: 10000 overriding model: 100000\n",
      "[2024-07-27 11:00:32,342 INFO] Option: early_stopping , value: 10 overriding model: 0\n",
      "[2024-07-27 11:00:32,342 INFO] Option: optim , value: adam overriding model: \n",
      "[2024-07-27 11:00:32,342 INFO] Option: max_grad_norm , value: 0.5 overriding model: 0.0\n",
      "[2024-07-27 11:00:32,342 INFO] Option: dropout , value: [0.1, 0.1, 0.1] overriding model: [0.1]\n",
      "[2024-07-27 11:00:32,342 INFO] Option: attention_dropout , value: [0.1, 0.1, 0.1] overriding model: [0.1]\n",
      "[2024-07-27 11:00:32,342 INFO] Option: dropout_steps , value: [0, 15000, 30000] overriding model: [0]\n",
      "[2024-07-27 11:00:32,342 INFO] Option: average_decay , value: 0.0005 overriding model: 0.0\n",
      "[2024-07-27 11:00:32,342 INFO] Option: learning_rate , value: 2.0 overriding model: 5e-05\n",
      "[2024-07-27 11:00:32,342 INFO] Option: decay_method , value: noam overriding model: none\n",
      "[2024-07-27 11:00:32,342 INFO] Option: warmup_steps , value: 100 overriding model: 4000\n",
      "[2024-07-27 11:00:32,342 INFO] Option: log_file , value: /root/projects/zindi/nmt_train/trainnllb-200-600M-zindi_V2.log overriding model: \n",
      "[2024-07-27 11:00:32,342 INFO] Option: report_every , value: 10 overriding model: 100\n",
      "[2024-07-27 11:00:32,342 INFO] Option: _all_transform , value: {'prefix', 'suffix', 'sentencepiece', 'filtertoolong'} overriding model: {'filtertoolong'}\n",
      "[2024-07-27 11:00:32,343 INFO] Building model...\n",
      "[2024-07-27 11:00:41,437 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2024-07-27 11:00:41,437 INFO] Non quantized layer compute is fp16\n",
      "[2024-07-27 11:00:41,437 INFO] Updating vocabulary embeddings with checkpoint embeddings\n",
      "[2024-07-27 11:00:43,269 INFO] src: 14782 new tokens\n",
      "[2024-07-27 11:00:47,265 INFO] tgt: 14782 new tokens\n",
      "[2024-07-27 11:00:49,823 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(270987, 1024, padding_idx=2)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0-23): 24 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (linear_values): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (linear_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (w_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(270987, 1024, padding_idx=2)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0-23): 24 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (linear_values): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (linear_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (w_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (layer_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (linear_values): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (linear_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=1024, out_features=270987, bias=True)\n",
      ")\n",
      "[2024-07-27 11:00:49,831 INFO] encoder: 579802112\n",
      "[2024-07-27 11:00:49,831 INFO] decoder: 403393163\n",
      "[2024-07-27 11:00:49,831 INFO] * number of parameters: 983195275\n",
      "[2024-07-27 11:00:49,834 INFO] Trainable parameters = {'torch.float32': 983195275, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-07-27 11:00:49,834 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-07-27 11:00:49,834 INFO]  * src vocab size = 270987\n",
      "[2024-07-27 11:00:49,834 INFO]  * tgt vocab size = 270987\n",
      "[2024-07-27 11:00:50,405 INFO] Starting training on GPU: [0]\n",
      "[2024-07-27 11:00:50,405 INFO] Start training loop without validation...\n",
      "[2024-07-27 11:00:50,405 INFO] Scoring with: None\n",
      "[2024-07-27 11:00:52,725 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2024-07-27 11:00:54,935 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2024-07-27 11:00:57,141 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2024-07-27 11:00:59,319 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2024-07-27 11:01:01,536 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2024-07-27 11:01:03,835 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2024-07-27 11:01:06,067 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2024-07-27 11:01:08,174 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 2\n",
      "[2024-07-27 11:01:08,174 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 2\n",
      "[2024-07-27 11:01:08,175 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 2\n",
      "[2024-07-27 11:01:08,175 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 2\n",
      "[2024-07-27 11:01:08,176 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 2\n",
      "[2024-07-27 11:01:08,195 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 2\n",
      "[2024-07-27 11:01:08,198 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 2\n",
      "[2024-07-27 11:01:08,211 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 3\n",
      "[2024-07-27 11:01:08,212 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 3\n",
      "[2024-07-27 11:01:08,212 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 3\n",
      "[2024-07-27 11:01:08,213 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 3\n",
      "[2024-07-27 11:01:08,214 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 3\n",
      "[2024-07-27 11:01:08,237 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 3\n",
      "[2024-07-27 11:01:08,243 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 3\n",
      "[2024-07-27 11:01:08,341 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2024-07-27 11:01:08,376 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 2\n",
      "[2024-07-27 11:01:08,449 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 4\n",
      "[2024-07-27 11:01:08,453 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 4\n",
      "[2024-07-27 11:01:08,455 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 3\n",
      "[2024-07-27 11:01:08,455 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 4\n",
      "[2024-07-27 11:01:08,457 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 4\n",
      "[2024-07-27 11:01:08,462 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 4\n",
      "[2024-07-27 11:01:08,486 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 4\n",
      "[2024-07-27 11:01:08,486 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 5\n",
      "[2024-07-27 11:01:08,487 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 4\n",
      "[2024-07-27 11:01:08,490 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 5\n",
      "[2024-07-27 11:01:08,493 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 5\n",
      "[2024-07-27 11:01:08,494 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 5\n",
      "[2024-07-27 11:01:08,500 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 5\n",
      "[2024-07-27 11:01:08,524 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 5\n",
      "[2024-07-27 11:01:08,525 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 5\n",
      "[2024-07-27 11:01:08,525 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 6\n",
      "[2024-07-27 11:01:08,529 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 6\n",
      "[2024-07-27 11:01:08,531 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 6\n",
      "[2024-07-27 11:01:08,533 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 6\n",
      "[2024-07-27 11:01:08,538 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 6\n",
      "[2024-07-27 11:01:08,562 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 6\n",
      "[2024-07-27 11:01:08,563 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 7\n",
      "[2024-07-27 11:01:08,564 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 6\n",
      "[2024-07-27 11:01:08,566 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 7\n",
      "[2024-07-27 11:01:08,569 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 7\n",
      "[2024-07-27 11:01:08,570 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 7\n",
      "[2024-07-27 11:01:08,571 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 4\n",
      "[2024-07-27 11:01:08,575 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 7\n",
      "[2024-07-27 11:01:08,600 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 7\n",
      "[2024-07-27 11:01:08,600 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 8\n",
      "[2024-07-27 11:01:08,601 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 7\n",
      "[2024-07-27 11:01:08,603 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 8\n",
      "[2024-07-27 11:01:08,607 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 8\n",
      "[2024-07-27 11:01:08,607 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 8\n",
      "[2024-07-27 11:01:08,608 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 5\n",
      "[2024-07-27 11:01:08,612 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 8\n",
      "[2024-07-27 11:01:08,637 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 8\n",
      "[2024-07-27 11:01:08,639 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 9\n",
      "[2024-07-27 11:01:08,639 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 8\n",
      "[2024-07-27 11:01:08,641 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 9\n",
      "[2024-07-27 11:01:08,645 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 9\n",
      "[2024-07-27 11:01:08,646 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 9\n",
      "[2024-07-27 11:01:08,647 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 6\n",
      "[2024-07-27 11:01:08,650 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 9\n",
      "[2024-07-27 11:01:08,676 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 9\n",
      "[2024-07-27 11:01:08,676 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 10\n",
      "[2024-07-27 11:01:08,678 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 9\n",
      "[2024-07-27 11:01:08,678 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 10\n",
      "[2024-07-27 11:01:08,682 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 10\n",
      "[2024-07-27 11:01:08,683 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 10\n",
      "[2024-07-27 11:01:08,684 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 7\n",
      "[2024-07-27 11:01:08,687 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 10\n",
      "[2024-07-27 11:01:08,713 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 10\n",
      "[2024-07-27 11:01:08,714 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 11\n",
      "[2024-07-27 11:01:08,715 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 10\n",
      "[2024-07-27 11:01:08,716 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 11\n",
      "[2024-07-27 11:01:08,720 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 11\n",
      "[2024-07-27 11:01:08,721 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 11\n",
      "[2024-07-27 11:01:08,722 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 8\n",
      "[2024-07-27 11:01:08,725 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 11\n",
      "[2024-07-27 11:01:08,752 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 11\n",
      "[2024-07-27 11:01:08,753 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 11\n",
      "[2024-07-27 11:01:08,761 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 9\n",
      "[2024-07-27 11:01:08,799 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 10\n",
      "[2024-07-27 11:01:08,836 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 11\n",
      "[2024-07-27 11:01:08,916 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 12\n",
      "[2024-07-27 11:01:08,917 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 12\n",
      "[2024-07-27 11:01:08,923 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 12\n",
      "[2024-07-27 11:01:08,926 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 12\n",
      "[2024-07-27 11:01:08,927 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 12\n",
      "[2024-07-27 11:01:08,950 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 12\n",
      "[2024-07-27 11:01:08,953 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 13\n",
      "[2024-07-27 11:01:08,954 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 12\n",
      "[2024-07-27 11:01:08,954 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 13\n",
      "[2024-07-27 11:01:08,961 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 13\n",
      "[2024-07-27 11:01:08,963 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 13\n",
      "[2024-07-27 11:01:08,965 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 13\n",
      "[2024-07-27 11:01:08,988 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 13\n",
      "[2024-07-27 11:01:08,991 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 13\n",
      "[2024-07-27 11:01:08,991 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 14\n",
      "[2024-07-27 11:01:08,993 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 14\n",
      "[2024-07-27 11:01:09,000 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 14\n",
      "[2024-07-27 11:01:09,000 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 14\n",
      "[2024-07-27 11:01:09,004 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 14\n",
      "[2024-07-27 11:01:09,013 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 12\n",
      "[2024-07-27 11:01:09,026 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 14\n",
      "[2024-07-27 11:01:09,028 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 15\n",
      "[2024-07-27 11:01:09,029 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 14\n",
      "[2024-07-27 11:01:09,030 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 15\n",
      "[2024-07-27 11:01:09,037 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 15\n",
      "[2024-07-27 11:01:09,038 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 15\n",
      "[2024-07-27 11:01:09,042 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 15\n",
      "[2024-07-27 11:01:09,050 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 13\n",
      "[2024-07-27 11:01:09,064 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 15\n",
      "[2024-07-27 11:01:09,066 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 16\n",
      "[2024-07-27 11:01:09,067 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 15\n",
      "[2024-07-27 11:01:09,068 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 16\n",
      "[2024-07-27 11:01:09,075 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 16\n",
      "[2024-07-27 11:01:09,075 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 16\n",
      "[2024-07-27 11:01:09,080 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 16\n",
      "[2024-07-27 11:01:09,089 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 14\n",
      "[2024-07-27 11:01:09,102 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 16\n",
      "[2024-07-27 11:01:09,104 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 16\n",
      "[2024-07-27 11:01:09,104 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 17\n",
      "[2024-07-27 11:01:09,106 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 17\n",
      "[2024-07-27 11:01:09,113 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 17\n",
      "[2024-07-27 11:01:09,113 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 17\n",
      "[2024-07-27 11:01:09,118 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 17\n",
      "[2024-07-27 11:01:09,127 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 15\n",
      "[2024-07-27 11:01:09,140 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 17\n",
      "[2024-07-27 11:01:09,142 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 18\n",
      "[2024-07-27 11:01:09,143 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 17\n",
      "[2024-07-27 11:01:09,144 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 18\n",
      "[2024-07-27 11:01:09,150 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 18\n",
      "[2024-07-27 11:01:09,151 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 18\n",
      "[2024-07-27 11:01:09,155 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 18\n",
      "[2024-07-27 11:01:09,167 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 16\n",
      "[2024-07-27 11:01:09,178 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 18\n",
      "[2024-07-27 11:01:09,180 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 18\n",
      "[2024-07-27 11:01:09,180 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 19\n",
      "[2024-07-27 11:01:09,182 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 19\n",
      "[2024-07-27 11:01:09,188 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 19\n",
      "[2024-07-27 11:01:09,190 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 19\n",
      "[2024-07-27 11:01:09,194 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 19\n",
      "[2024-07-27 11:01:09,207 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 17\n",
      "[2024-07-27 11:01:09,217 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 19\n",
      "[2024-07-27 11:01:09,219 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 19\n",
      "[2024-07-27 11:01:09,246 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 18\n",
      "[2024-07-27 11:01:09,287 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 19\n",
      "[2024-07-27 11:01:09,459 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 20\n",
      "[2024-07-27 11:01:09,460 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 20\n",
      "[2024-07-27 11:01:09,470 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 20\n",
      "[2024-07-27 11:01:09,472 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 20\n",
      "[2024-07-27 11:01:09,475 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 20\n",
      "[2024-07-27 11:01:09,495 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 20\n",
      "[2024-07-27 11:01:09,496 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 21\n",
      "[2024-07-27 11:01:09,498 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 21\n",
      "[2024-07-27 11:01:09,505 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 20\n",
      "[2024-07-27 11:01:09,507 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 21\n",
      "[2024-07-27 11:01:09,510 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 21\n",
      "[2024-07-27 11:01:09,513 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 21\n",
      "[2024-07-27 11:01:09,533 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 21\n",
      "[2024-07-27 11:01:09,535 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 22\n",
      "[2024-07-27 11:01:09,535 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 20\n",
      "[2024-07-27 11:01:09,537 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 22\n",
      "[2024-07-27 11:01:09,543 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 21\n",
      "[2024-07-27 11:01:09,545 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 22\n",
      "[2024-07-27 11:01:09,549 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 22\n",
      "[2024-07-27 11:01:09,551 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 22\n",
      "[2024-07-27 11:01:09,571 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 22\n",
      "[2024-07-27 11:01:09,572 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 23\n",
      "[2024-07-27 11:01:09,573 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 21\n",
      "[2024-07-27 11:01:09,576 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 23\n",
      "[2024-07-27 11:01:09,582 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 22\n",
      "[2024-07-27 11:01:09,583 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 23\n",
      "[2024-07-27 11:01:09,587 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 23\n",
      "[2024-07-27 11:01:09,588 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 23\n",
      "[2024-07-27 11:01:09,609 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 23\n",
      "[2024-07-27 11:01:09,610 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 24\n",
      "[2024-07-27 11:01:09,612 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 22\n",
      "[2024-07-27 11:01:09,614 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 24\n",
      "[2024-07-27 11:01:09,620 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 23\n",
      "[2024-07-27 11:01:09,620 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 24\n",
      "[2024-07-27 11:01:09,625 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 24\n",
      "[2024-07-27 11:01:09,626 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 24\n",
      "[2024-07-27 11:01:09,649 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 24\n",
      "[2024-07-27 11:01:09,649 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 25\n",
      "[2024-07-27 11:01:09,650 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 23\n",
      "[2024-07-27 11:01:09,655 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 25\n",
      "[2024-07-27 11:01:09,659 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 24\n",
      "[2024-07-27 11:01:09,659 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 25\n",
      "[2024-07-27 11:01:09,664 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 25\n",
      "[2024-07-27 11:01:09,665 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 25\n",
      "[2024-07-27 11:01:09,686 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 26\n",
      "[2024-07-27 11:01:09,688 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 25\n",
      "[2024-07-27 11:01:09,688 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 24\n",
      "[2024-07-27 11:01:09,692 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 26\n",
      "[2024-07-27 11:01:09,696 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 25\n",
      "[2024-07-27 11:01:09,696 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 26\n",
      "[2024-07-27 11:01:09,702 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 26\n",
      "[2024-07-27 11:01:09,702 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 26\n",
      "[2024-07-27 11:01:09,725 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 27\n",
      "[2024-07-27 11:01:09,725 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 26\n",
      "[2024-07-27 11:01:09,727 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 25\n",
      "[2024-07-27 11:01:09,732 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 27\n",
      "[2024-07-27 11:01:09,734 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 26\n",
      "[2024-07-27 11:01:09,735 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 27\n",
      "[2024-07-27 11:01:09,740 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 27\n",
      "[2024-07-27 11:01:09,741 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 27\n",
      "[2024-07-27 11:01:09,763 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 28\n",
      "[2024-07-27 11:01:09,764 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 27\n",
      "[2024-07-27 11:01:09,764 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 26\n",
      "[2024-07-27 11:01:09,770 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 28\n",
      "[2024-07-27 11:01:09,772 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 28\n",
      "[2024-07-27 11:01:09,773 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 27\n",
      "[2024-07-27 11:01:09,777 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 28\n",
      "[2024-07-27 11:01:09,779 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 28\n",
      "[2024-07-27 11:01:09,802 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 28\n",
      "[2024-07-27 11:01:09,803 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 27\n",
      "[2024-07-27 11:01:09,811 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 28\n",
      "[2024-07-27 11:01:09,841 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 28\n",
      "[2024-07-27 11:01:10,104 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 29\n",
      "[2024-07-27 11:01:10,115 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 29\n",
      "[2024-07-27 11:01:10,117 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 29\n",
      "[2024-07-27 11:01:10,126 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 29\n",
      "[2024-07-27 11:01:10,128 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 29\n",
      "[2024-07-27 11:01:10,137 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 29\n",
      "[2024-07-27 11:01:10,142 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 30\n",
      "[2024-07-27 11:01:10,153 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 30\n",
      "[2024-07-27 11:01:10,155 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 30\n",
      "[2024-07-27 11:01:10,155 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 29\n",
      "[2024-07-27 11:01:10,163 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 29\n",
      "[2024-07-27 11:01:10,165 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 30\n",
      "[2024-07-27 11:01:10,166 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 30\n",
      "[2024-07-27 11:01:10,175 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 30\n",
      "[2024-07-27 11:01:10,180 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 31\n",
      "[2024-07-27 11:01:10,191 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 31\n",
      "[2024-07-27 11:01:10,192 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 31\n",
      "[2024-07-27 11:01:10,194 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 30\n",
      "[2024-07-27 11:01:10,202 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 30\n",
      "[2024-07-27 11:01:10,203 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 31\n",
      "[2024-07-27 11:01:10,204 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 31\n",
      "[2024-07-27 11:01:10,213 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 31\n",
      "[2024-07-27 11:01:10,217 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 32\n",
      "[2024-07-27 11:01:10,228 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 32\n",
      "[2024-07-27 11:01:10,230 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 32\n",
      "[2024-07-27 11:01:10,231 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 31\n",
      "[2024-07-27 11:01:10,239 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 31\n",
      "[2024-07-27 11:01:10,241 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 32\n",
      "[2024-07-27 11:01:10,242 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 32\n",
      "[2024-07-27 11:01:10,250 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 32\n",
      "[2024-07-27 11:01:10,256 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 33\n",
      "[2024-07-27 11:01:10,267 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 33\n",
      "[2024-07-27 11:01:10,268 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 33\n",
      "[2024-07-27 11:01:10,270 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 32\n",
      "[2024-07-27 11:01:10,277 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 32\n",
      "[2024-07-27 11:01:10,279 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 33\n",
      "[2024-07-27 11:01:10,281 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 33\n",
      "[2024-07-27 11:01:10,289 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 33\n",
      "[2024-07-27 11:01:10,293 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 34\n",
      "[2024-07-27 11:01:10,305 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 34\n",
      "[2024-07-27 11:01:10,305 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 34\n",
      "[2024-07-27 11:01:10,307 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 33\n",
      "[2024-07-27 11:01:10,316 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 33\n",
      "[2024-07-27 11:01:10,316 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 34\n",
      "[2024-07-27 11:01:10,319 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 34\n",
      "[2024-07-27 11:01:10,327 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 34\n",
      "[2024-07-27 11:01:10,345 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 34\n",
      "[2024-07-27 11:01:10,354 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 34\n",
      "[2024-07-27 11:01:37,265 INFO] Step 10/10000; acc: 25.0; ppl: 871.3; xent: 6.8; lr: 0.00069; sents:     140; bsz:   28/  34/ 2;  47/ 57 tok/s;     47 sec;\n",
      "[2024-07-27 11:01:52,195 INFO] Step 20/10000; acc: 23.2; ppl: 888.7; xent: 6.8; lr: 0.00131; sents:     112; bsz:   27/  33/ 1; 143/176 tok/s;     62 sec;\n",
      "[2024-07-27 11:02:07,178 INFO] Step 30/10000; acc: 25.4; ppl: 804.8; xent: 6.7; lr: 0.00194; sents:     132; bsz:   23/  28/ 2; 121/148 tok/s;     77 sec;\n",
      "[2024-07-27 11:02:22,206 INFO] Step 40/10000; acc: 19.6; ppl: 1022.6; xent: 6.9; lr: 0.00256; sents:     105; bsz:   33/  38/ 1; 177/203 tok/s;     92 sec;\n",
      "[2024-07-27 11:02:37,120 INFO] Step 50/10000; acc: 23.3; ppl: 793.7; xent: 6.7; lr: 0.00319; sents:     104; bsz:   27/  31/ 1; 146/164 tok/s;    107 sec;\n",
      "[2024-07-27 11:02:52,061 INFO] Step 60/10000; acc: 25.5; ppl: 715.3; xent: 6.6; lr: 0.00381; sents:     130; bsz:   26/  32/ 2; 138/171 tok/s;    122 sec;\n",
      "[2024-07-27 11:03:07,181 INFO] Step 70/10000; acc: 22.1; ppl: 992.3; xent: 6.9; lr: 0.00444; sents:     119; bsz:   29/  34/ 1; 153/178 tok/s;    137 sec;\n",
      "[2024-07-27 11:03:22,331 INFO] Step 80/10000; acc: 27.3; ppl: 660.1; xent: 6.5; lr: 0.00506; sents:     138; bsz:   25/  29/ 2; 133/154 tok/s;    152 sec;\n",
      "[2024-07-27 11:03:37,294 INFO] Step 90/10000; acc: 24.9; ppl: 732.1; xent: 6.6; lr: 0.00569; sents:     113; bsz:   23/  28/ 1; 124/149 tok/s;    167 sec;\n",
      "[2024-07-27 11:03:52,178 INFO] Step 100/10000; acc: 19.8; ppl: 1060.9; xent: 7.0; lr: 0.00622; sents:      97; bsz:   26/  32/ 1; 138/171 tok/s;    182 sec;\n",
      "[2024-07-27 11:04:07,057 INFO] Step 110/10000; acc: 18.7; ppl: 1139.3; xent: 7.0; lr: 0.00593; sents:      93; bsz:   27/  32/ 1; 146/171 tok/s;    197 sec;\n",
      "[2024-07-27 11:04:21,966 INFO] Step 120/10000; acc: 23.3; ppl: 872.8; xent: 6.8; lr: 0.00568; sents:     108; bsz:   24/  30/ 1; 130/160 tok/s;    212 sec;\n",
      "[2024-07-27 11:04:36,918 INFO] Step 130/10000; acc: 19.8; ppl: 1084.5; xent: 7.0; lr: 0.00546; sents:     111; bsz:   33/  34/ 1; 174/182 tok/s;    227 sec;\n",
      "[2024-07-27 11:04:52,094 INFO] Step 140/10000; acc: 26.1; ppl: 614.2; xent: 6.4; lr: 0.00526; sents:     120; bsz:   19/  25/ 2; 100/132 tok/s;    242 sec;\n",
      "[2024-07-27 11:05:07,249 INFO] Step 150/10000; acc: 22.6; ppl: 860.3; xent: 6.8; lr: 0.00509; sents:     111; bsz:   27/  30/ 1; 140/158 tok/s;    257 sec;\n",
      "[2024-07-27 11:05:22,253 INFO] Step 160/10000; acc: 21.8; ppl: 1000.8; xent: 6.9; lr: 0.00493; sents:     115; bsz:   30/  33/ 1; 159/177 tok/s;    272 sec;\n",
      "[2024-07-27 11:05:37,235 INFO] Step 170/10000; acc: 19.4; ppl: 908.3; xent: 6.8; lr: 0.00478; sents:     107; bsz:   34/  35/ 1; 180/190 tok/s;    287 sec;\n",
      "[2024-07-27 11:05:52,175 INFO] Step 180/10000; acc: 24.0; ppl: 791.8; xent: 6.7; lr: 0.00465; sents:     113; bsz:   25/  29/ 1; 134/158 tok/s;    302 sec;\n",
      "[2024-07-27 11:06:07,225 INFO] Step 190/10000; acc: 27.2; ppl: 538.6; xent: 6.3; lr: 0.00452; sents:     135; bsz:   25/  30/ 2; 134/157 tok/s;    317 sec;\n",
      "[2024-07-27 11:06:22,218 INFO] Step 200/10000; acc: 27.0; ppl: 450.4; xent: 6.1; lr: 0.00441; sents:     125; bsz:   26/  30/ 2; 139/160 tok/s;    332 sec;\n",
      "[2024-07-27 11:06:37,317 INFO] Step 210/10000; acc: 20.3; ppl: 737.4; xent: 6.6; lr: 0.00430; sents:      92; bsz:   31/  33/ 1; 162/174 tok/s;    347 sec;\n",
      "[2024-07-27 11:06:52,277 INFO] Step 220/10000; acc: 23.3; ppl: 732.9; xent: 6.6; lr: 0.00420; sents:     103; bsz:   26/  32/ 1; 140/169 tok/s;    362 sec;\n",
      "[2024-07-27 11:07:07,189 INFO] Step 230/10000; acc: 22.5; ppl: 643.1; xent: 6.5; lr: 0.00411; sents:     107; bsz:   27/  32/ 1; 146/170 tok/s;    377 sec;\n",
      "[2024-07-27 11:07:22,508 INFO] Step 240/10000; acc: 25.7; ppl: 499.5; xent: 6.2; lr: 0.00403; sents:     109; bsz:   23/  29/ 1; 119/150 tok/s;    392 sec;\n",
      "[2024-07-27 11:07:37,749 INFO] Step 250/10000; acc: 22.2; ppl: 739.2; xent: 6.6; lr: 0.00394; sents:      96; bsz:   30/  34/ 1; 158/177 tok/s;    407 sec;\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%cd /root/projects/zindi/nmt_train/models/\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "!onmt_train -config config2.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nmt-train-93Y4ewMI-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
